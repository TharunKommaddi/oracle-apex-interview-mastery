<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Oracle SQL Interview Questions - APEX Interview Mastery</title>
    <meta name="description" content="Master Oracle SQL with comprehensive interview questions from basic to advanced levels.">
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Styles -->
    <link rel="stylesheet" href="assets/css/style.css">
    
    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='0.9em' font-size='90'>üóÑÔ∏è</text></svg>">
</head>
<body>
    <header class="header">
        <div class="nav-container">
            <a href="index.html" class="logo">
                <i class="fas fa-code"></i>
                APEX Interview Mastery
            </a>
            <nav>
                <ul class="nav-menu" id="navMenu">
                    <li class="nav-item">
                        <a href="index.html">
                            <i class="fas fa-home"></i> Home
                        </a>
                    </li>
                    <li class="nav-item">
                        <a href="oracle-sql.html" class="active">
                            <i class="fas fa-database"></i> Oracle SQL
                        </a>
                    </li>
                    <li class="nav-item">
                        <a href="plsql.html">
                            <i class="fas fa-code-branch"></i> PL/SQL
                        </a>
                    </li>
                    <li class="nav-item">
                        <a href="oracle-apex.html">
                            <i class="fas fa-layer-group"></i> Oracle APEX
                        </a>
                    </li>
                    <li class="nav-item dropdown">
                        <a href="#" class="dropdown-toggle">
                            <i class="fas fa-paint-brush"></i> Frontend <i class="fas fa-chevron-down"></i>
                        </a>
                        <ul class="dropdown-menu">
                            <li><a href="html-questions.html"><i class="fab fa-html5"></i> HTML</a></li>
                            <li><a href="css-questions.html"><i class="fab fa-css3-alt"></i> CSS</a></li>
                            <li><a href="javascript-questions.html"><i class="fab fa-js"></i> JavaScript</a></li>
                            <li><a href="jquery-questions.html"><i class="fas fa-dollar-sign"></i> jQuery</a></li>
                        </ul>
                    </li>
                </ul>
                <button class="mobile-menu-toggle" onclick="toggleMobileMenu()" aria-label="Toggle mobile menu">
                    <i class="fas fa-bars"></i>
                </button>
            </nav>
        </div>
    </header>

    <section class="page-header">
        <h1 class="page-title">Oracle SQL Interview Questions</h1>
        <p class="page-subtitle">Master Oracle SQL with 82 comprehensive questions from basic to advanced levels</p>
    </section>

    <div class="container">
        <div class="filter-section">
            <div class="filter-title">
                <i class="fas fa-database"></i> Filter Questions
            </div>
            <div class="filter-tabs">
                <button class="filter-tab active" onclick="filterQuestions('all')">All Questions</button>
                <button class="filter-tab" onclick="filterQuestions('basic')">Basic</button>
                <button class="filter-tab" onclick="filterQuestions('intermediate')">Intermediate</button>
                <button class="filter-tab" onclick="filterQuestions('advanced')">Advanced</button>
            </div>
            <div class="search-container">
                <i class="fas fa-search search-icon"></i>
                <input type="text" class="search-input" placeholder="Search SQL questions..." 
                       onkeyup="searchQuestions()" id="searchInput" aria-label="Search questions">
            </div>
        </div>

        <div id="questionsContainer" class="questions-container">
            <!-- Questions will be loaded here by JavaScript -->
        </div>
    </div>

    <footer class="footer">
        <div class="footer-content">
            <h3>Ready to Master Oracle SQL?</h3>
            <p>Practice these 82 essential questions to excel in your Oracle APEX interviews</p>
            <div class="footer-links">
                <a href="index.html">Home</a>
                <a href="oracle-apex.html">APEX Questions</a>
                <a href="plsql.html">PL/SQL Questions</a>
            </div>
        </div>
    </footer>

    <script src="assets/js/script.js"></script>
    <script>
        // Oracle SQL Questions Data - All 82 Questions Converted from MySQL


        // Oracle SQL Questions Data - Expanded with Internet Research (120+ Questions)
const oracleSqlQuestions = [
   // EXISTING QUESTIONS (1-32) - Your current questions
   {
       id: 1,
       category: 'basic',
       difficulty: 'basic',
       question: 'How can you find the Nth highest salary from a table in Oracle?',
       answer: 'There are multiple approaches to find the Nth highest salary in Oracle using ranking functions, subqueries, and analytical functions.',
       language: 'Oracle SQL',
       code: `-- Method 1: Using ROW_NUMBER() - Most efficient for unique values
SELECT salary 
FROM (
   SELECT salary, ROW_NUMBER() OVER (ORDER BY salary DESC) as rn
   FROM employee
   WHERE salary IS NOT NULL
)
WHERE rn = :N;

-- Method 2: Using DENSE_RANK() - Handles duplicates better
SELECT DISTINCT salary 
FROM (
   SELECT salary, DENSE_RANK() OVER (ORDER BY salary DESC) as rnk
   FROM employee
   WHERE salary IS NOT NULL
)
WHERE rnk = :N;

-- Method 3: Using RANK() - Standard ranking with gaps
SELECT DISTINCT salary 
FROM (
   SELECT salary, RANK() OVER (ORDER BY salary DESC) as rank_num
   FROM employee
   WHERE salary IS NOT NULL
)
WHERE rank_num = :N;

-- Method 4: Using ROWNUM (Oracle-specific)
SELECT salary
FROM (
   SELECT DISTINCT salary
   FROM employee
   WHERE salary IS NOT NULL
   ORDER BY salary DESC
)
WHERE ROWNUM = :N;

-- Method 5: Using OFFSET and FETCH (Oracle 12c+)
SELECT DISTINCT salary
FROM employee
WHERE salary IS NOT NULL
ORDER BY salary DESC
OFFSET (:N - 1) ROWS FETCH NEXT 1 ROWS ONLY;`
   },
   {
       id: 2,
       category: 'basic',
       difficulty: 'basic',
       question: 'Explain JOIN and different types of JOIN in Oracle SQL.',
       answer: 'JOIN is used to combine rows from two or more tables based on a related column between them. Oracle supports multiple JOIN types.',
       language: 'Oracle SQL',
       code: `-- INNER JOIN: Returns records that have matching values in both tables
SELECT e.employee_id, e.first_name, d.department_name
FROM employees e
INNER JOIN departments d ON e.department_id = d.department_id;

-- LEFT OUTER JOIN: Returns all records from left table, matched from right
SELECT e.employee_id, e.first_name, d.department_name
FROM employees e
LEFT OUTER JOIN departments d ON e.department_id = d.department_id;

-- RIGHT OUTER JOIN: Returns all records from right table, matched from left
SELECT e.employee_id, e.first_name, d.department_name
FROM employees e
RIGHT OUTER JOIN departments d ON e.department_id = d.department_id;

-- FULL OUTER JOIN: Returns all records when there's a match in either table
SELECT e.employee_id, e.first_name, d.department_name
FROM employees e
FULL OUTER JOIN departments d ON e.department_id = d.department_id;

-- CROSS JOIN: Cartesian product of both tables
SELECT e.first_name, d.department_name
FROM employees e
CROSS JOIN departments d;

-- Self JOIN: Table joined with itself
SELECT e1.employee_id, e1.first_name, e2.first_name as manager_name
FROM employees e1
LEFT JOIN employees e2 ON e1.manager_id = e2.employee_id;`
   },
   
   // NEW QUESTIONS FROM INTERNET RESEARCH (33-120)
   
   // WINDOW FUNCTIONS & ANALYTICS (33-45)
   {
       id: 33,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'Explain the difference between ROW_NUMBER(), RANK(), and DENSE_RANK() window functions in Oracle.',
       answer: 'These are ranking window functions that assign ranks to rows, but they handle ties differently and have different use cases.',
       language: 'Oracle SQL',
       code: `-- Sample data setup
WITH sample_data AS (
   SELECT 'John' as name, 85 as score FROM dual UNION ALL
   SELECT 'Alice', 92 FROM dual UNION ALL
   SELECT 'Bob', 85 FROM dual UNION ALL
   SELECT 'Carol', 78 FROM dual UNION ALL
   SELECT 'David', 92 FROM dual
)
SELECT name, score,
      ROW_NUMBER() OVER (ORDER BY score DESC) as row_num,
      RANK() OVER (ORDER BY score DESC) as rank_val,
      DENSE_RANK() OVER (ORDER BY score DESC) as dense_rank_val
FROM sample_data;

-- Results explanation:
-- ROW_NUMBER(): Always assigns unique sequential numbers (1,2,3,4,5)
-- RANK(): Assigns same rank for ties, skips next ranks (1,1,3,4,4) 
-- DENSE_RANK(): Assigns same rank for ties, no gaps (1,1,2,3,3)

-- Practical example: Top 3 salaries per department
SELECT department_id, employee_id, salary,
      DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as salary_rank
FROM employees
WHERE DENSE_RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) <= 3;

-- Performance tip: Use ROW_NUMBER() when you need unique ranking
-- Use RANK() when gaps in ranking are acceptable  
-- Use DENSE_RANK() when you need consecutive ranking without gaps`
   },
   {
       id: 34,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you calculate running totals and moving averages using Oracle window functions?',
       answer: 'Use window functions with frame specifications to calculate cumulative values and moving averages over ordered data sets.',
       language: 'Oracle SQL',
       code: `-- Running total (cumulative sum)
SELECT employee_id, hire_date, salary,
      SUM(salary) OVER (ORDER BY hire_date 
                       ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as running_total,
      -- Alternative syntax (same result)
      SUM(salary) OVER (ORDER BY hire_date) as running_total_alt
FROM employees;

-- Moving average (last 3 months)
SELECT month_year, sales_amount,
      AVG(sales_amount) OVER (ORDER BY month_year 
                             ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) as moving_avg_3months,
      -- Moving total for last 3 months  
      SUM(sales_amount) OVER (ORDER BY month_year 
                             ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) as moving_total_3months
FROM monthly_sales;

-- Advanced frame specifications
SELECT employee_id, salary, hire_date,
      -- Running average from start to current row
      AVG(salary) OVER (ORDER BY hire_date 
                       ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as running_avg,
      -- Centered moving average (1 before, current, 1 after)
      AVG(salary) OVER (ORDER BY hire_date 
                       ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) as centered_avg,
      -- Percentage of running total
      salary / SUM(salary) OVER (ORDER BY hire_date 
                                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) * 100 as pct_of_running_total
FROM employees;

-- Partitioned running totals (reset for each group)
SELECT department_id, employee_id, salary,
      SUM(salary) OVER (PARTITION BY department_id 
                       ORDER BY hire_date 
                       ROWS UNBOUNDED PRECEDING) as dept_running_total
FROM employees;`
   },
   {
       id: 35,
       category: 'intermediate',
       difficulty: 'intermediate',
       question: 'What are the different window frame specifications in Oracle and when to use them?',
       answer: 'Oracle window functions support various frame specifications using ROWS and RANGE clauses to define the window of rows for calculations.',
       language: 'Oracle SQL',
       code: `-- Frame specification syntax and examples
SELECT employee_id, salary, hire_date,
      
      -- ROWS BETWEEN: Physical row-based frames
      SUM(salary) OVER (ORDER BY hire_date 
                       ROWS BETWEEN 2 PRECEDING AND 1 FOLLOWING) as rows_frame,
      
      -- RANGE BETWEEN: Logical value-based frames  
      SUM(salary) OVER (ORDER BY salary 
                       RANGE BETWEEN 1000 PRECEDING AND 1000 FOLLOWING) as range_frame,
      
      -- Default frame (RANGE UNBOUNDED PRECEDING)
      SUM(salary) OVER (ORDER BY hire_date) as default_frame,
      
      -- Current row only
      SUM(salary) OVER (ORDER BY hire_date 
                       ROWS BETWEEN CURRENT ROW AND CURRENT ROW) as current_only,
      
      -- All preceding rows
      SUM(salary) OVER (ORDER BY hire_date 
                       ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as all_preceding,
      
      -- All following rows  
      SUM(salary) OVER (ORDER BY hire_date 
                       ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) as all_following
FROM employees;

-- Practical example: Sales analysis with different frames
SELECT sale_date, daily_sales,
      -- 7-day moving average
      AVG(daily_sales) OVER (ORDER BY sale_date 
                            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) as moving_avg_7days,
      -- Year-to-date total
      SUM(daily_sales) OVER (PARTITION BY EXTRACT(YEAR FROM sale_date) 
                            ORDER BY sale_date) as ytd_total,
      -- Compare with same day last year
      LAG(daily_sales, 365) OVER (ORDER BY sale_date) as same_day_last_year
FROM daily_sales;`
   },
   
   // RECURSIVE CTEs & HIERARCHICAL QUERIES (36-42)
   {
       id: 36,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you write recursive CTEs to handle hierarchical data in Oracle?',
       answer: 'Recursive CTEs allow querying hierarchical data by defining an anchor member and recursive member that references itself until a termination condition is met.',
       language: 'Oracle SQL',
       code: `-- Recursive CTE for employee hierarchy
WITH RECURSIVE employee_hierarchy AS (
   -- Anchor member: Start with top-level managers
   SELECT employee_id, first_name, last_name, manager_id, 0 as level,
          CAST(first_name || ' ' || last_name AS VARCHAR2(1000)) as hierarchy_path
   FROM employees 
   WHERE manager_id IS NULL
   
   UNION ALL
   
   -- Recursive member: Find subordinates
   SELECT e.employee_id, e.first_name, e.last_name, e.manager_id, h.level + 1,
          CAST(h.hierarchy_path || ' -> ' || e.first_name || ' ' || e.last_name AS VARCHAR2(1000))
   FROM employees e
   INNER JOIN employee_hierarchy h ON e.manager_id = h.employee_id
   WHERE h.level < 10  -- Prevent infinite recursion
)
SELECT employee_id, first_name, last_name, level, hierarchy_path
FROM employee_hierarchy
ORDER BY level, last_name;

-- Organizational chart with indentation
WITH RECURSIVE org_chart AS (
   SELECT employee_id, first_name, last_name, manager_id, 0 as level
   FROM employees 
   WHERE manager_id IS NULL
   
   UNION ALL
   
   SELECT e.employee_id, e.first_name, e.last_name, e.manager_id, o.level + 1
   FROM employees e
   INNER JOIN org_chart o ON e.manager_id = o.employee_id
)
SELECT LPAD(' ', level * 4) || first_name || ' ' || last_name as org_structure,
      level,
      employee_id
FROM org_chart
ORDER BY level, last_name;

-- Find all subordinates of a specific manager
WITH RECURSIVE subordinates AS (
   -- Anchor: Specific manager
   SELECT employee_id, first_name, last_name, manager_id, 0 as level
   FROM employees 
   WHERE employee_id = 100  -- Specific manager ID
   
   UNION ALL
   
   -- Recursive: All subordinates
   SELECT e.employee_id, e.first_name, e.last_name, e.manager_id, s.level + 1
   FROM employees e
   INNER JOIN subordinates s ON e.manager_id = s.employee_id
)
SELECT * FROM subordinates WHERE level > 0;`
   },
   {
       id: 37,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'Compare Oracle CONNECT BY with Recursive CTEs for hierarchical queries.',
       answer: 'Oracle CONNECT BY is Oracle-specific syntax for hierarchical queries, while Recursive CTEs are SQL standard. Each has advantages and specific use cases.',
       language: 'Oracle SQL',
       code: `-- Oracle CONNECT BY (Oracle-specific)
SELECT LEVEL,
      LPAD(' ', (LEVEL-1)*2) || first_name || ' ' || last_name as employee_hierarchy,
      employee_id,
      manager_id,
      SYS_CONNECT_BY_PATH(first_name || ' ' || last_name, ' -> ') as path
FROM employees
START WITH manager_id IS NULL
CONNECT BY PRIOR employee_id = manager_id
ORDER SIBLINGS BY last_name;

-- CONNECT BY with NOCYCLE (prevents infinite loops)
SELECT LEVEL, employee_id, first_name, last_name, manager_id
FROM employees
START WITH manager_id IS NULL
CONNECT BY NOCYCLE PRIOR employee_id = manager_id;

-- Using CONNECT_BY_ISLEAF and CONNECT_BY_ISCYCLE
SELECT employee_id, first_name, last_name, LEVEL,
      CONNECT_BY_ISLEAF as is_leaf_node,
      CONNECT_BY_ISCYCLE as has_cycle
FROM employees
START WITH manager_id IS NULL
CONNECT BY NOCYCLE PRIOR employee_id = manager_id;

-- Recursive CTE equivalent (SQL Standard)
WITH RECURSIVE emp_hierarchy AS (
   SELECT employee_id, first_name, last_name, manager_id, 1 as level,
          CAST('/' || employee_id AS VARCHAR2(1000)) as path
   FROM employees 
   WHERE manager_id IS NULL
   
   UNION ALL
   
   SELECT e.employee_id, e.first_name, e.last_name, e.manager_id, h.level + 1,
          CAST(h.path || '/' || e.employee_id AS VARCHAR2(1000))
   FROM employees e
   INNER JOIN emp_hierarchy h ON e.manager_id = h.employee_id
   WHERE h.path NOT LIKE '%/' || e.employee_id || '/%'  -- Cycle detection
)
SELECT level, LPAD(' ', (level-1)*2) || first_name || ' ' || last_name as hierarchy,
      employee_id, manager_id, path
FROM emp_hierarchy
ORDER BY path;

-- Performance comparison:
-- CONNECT BY: Better performance for Oracle, more Oracle-specific functions
-- Recursive CTE: Standard SQL, portable, more explicit cycle detection
-- Use CONNECT BY for Oracle-only solutions, CTE for cross-platform compatibility`
   },
   {
       id: 38,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you handle cycles in hierarchical data using Oracle SQL?',
       answer: 'Oracle provides NOCYCLE keyword for CONNECT BY and manual cycle detection for Recursive CTEs to prevent infinite loops in hierarchical queries.',
       language: 'Oracle SQL',
       code: `-- Sample data with cycles
CREATE TABLE emp_with_cycles AS 
SELECT * FROM employees;

-- Create a cycle: Employee 101 reports to Employee 102, and 102 reports to 101
UPDATE emp_with_cycles SET manager_id = 102 WHERE employee_id = 101;
UPDATE emp_with_cycles SET manager_id = 101 WHERE employee_id = 102;

-- Method 1: CONNECT BY with NOCYCLE
SELECT LEVEL, employee_id, first_name, manager_id,
      CONNECT_BY_ISCYCLE as is_cycle,
      SYS_CONNECT_BY_PATH(employee_id, '/') as path
FROM emp_with_cycles
START WITH manager_id IS NULL
CONNECT BY NOCYCLE PRIOR employee_id = manager_id
ORDER BY path;

-- Method 2: Recursive CTE with manual cycle detection
WITH RECURSIVE emp_hierarchy AS (
   -- Anchor member
   SELECT employee_id, first_name, manager_id, 1 as level,
          CAST('/' || employee_id || '/' AS VARCHAR2(4000)) as path,
          0 as is_cycle
   FROM emp_with_cycles 
   WHERE manager_id IS NULL
   
   UNION ALL
   
   -- Recursive member with cycle detection
   SELECT e.employee_id, e.first_name, e.manager_id, h.level + 1,
          CAST(h.path || e.employee_id || '/' AS VARCHAR2(4000)) as path,
          CASE WHEN h.path LIKE '%/' || e.employee_id || '/%' THEN 1 ELSE 0 END as is_cycle
   FROM emp_with_cycles e
   INNER JOIN emp_hierarchy h ON e.manager_id = h.employee_id
   WHERE h.path NOT LIKE '%/' || e.employee_id || '/%'  -- Prevent cycles
      AND h.level < 20  -- Additional safety limit
)
SELECT level, employee_id, first_name, manager_id, is_cycle, path
FROM emp_hierarchy
ORDER BY level, employee_id;

-- Method 3: Using a visited nodes approach
WITH RECURSIVE hierarchy_safe AS (
   SELECT employee_id, first_name, manager_id, 1 as level,
          ARRAY[employee_id] as visited_nodes
   FROM emp_with_cycles 
   WHERE manager_id IS NULL
   
   UNION ALL
   
   SELECT e.employee_id, e.first_name, e.manager_id, h.level + 1,
          h.visited_nodes || e.employee_id
   FROM emp_with_cycles e
   INNER JOIN hierarchy_safe h ON e.manager_id = h.employee_id
   WHERE NOT (e.employee_id = ANY(h.visited_nodes))  -- Not already visited
      AND h.level < 50  -- Safety limit
)
SELECT * FROM hierarchy_safe;

-- Cleanup
DROP TABLE emp_with_cycles;`
   },
   
   // ORACLE-SPECIFIC FUNCTIONS (39-50)
   {
       id: 39,
       category: 'intermediate',
       difficulty: 'intermediate',
       question: 'Explain Oracle DECODE function and compare it with CASE statement.',
       answer: 'DECODE is Oracle-specific function for conditional logic, while CASE is SQL standard. Both can be used for if-then-else logic but have different syntax and capabilities.',
       language: 'Oracle SQL',
       code: `-- DECODE syntax: DECODE(expression, search1, result1, search2, result2, ..., default)
SELECT employee_id, first_name, department_id,
      DECODE(department_id, 
             10, 'Administration',
             20, 'Marketing', 
             30, 'Purchasing',
             40, 'Human Resources',
             50, 'Shipping',
             'Other') as department_name
FROM employees;

-- Equivalent CASE statement (SQL Standard)
SELECT employee_id, first_name, department_id,
      CASE department_id
          WHEN 10 THEN 'Administration'
          WHEN 20 THEN 'Marketing'
          WHEN 30 THEN 'Purchasing'
          WHEN 40 THEN 'Human Resources'
          WHEN 50 THEN 'Shipping'
          ELSE 'Other'
      END as department_name
FROM employees;

-- DECODE with expressions (Oracle-specific advantage)
SELECT employee_id, salary,
      DECODE(SIGN(salary - 50000),
             1, 'High Salary',
             0, 'Average Salary',
             -1, 'Low Salary') as salary_category
FROM employees;

-- CASE with complex conditions (more flexible than DECODE)
SELECT employee_id, salary, hire_date,
      CASE 
          WHEN salary > 80000 AND MONTHS_BETWEEN(SYSDATE, hire_date) > 60 THEN 'Senior High Earner'
          WHEN salary > 80000 THEN 'High Earner'
          WHEN salary > 40000 AND MONTHS_BETWEEN(SYSDATE, hire_date) > 24 THEN 'Experienced'
          WHEN salary > 40000 THEN 'Mid-level'
          ELSE 'Entry Level'
      END as employee_category
FROM employees;

-- DECODE for pivoting data
SELECT 
   SUM(DECODE(department_id, 10, salary, 0)) as admin_total,
   SUM(DECODE(department_id, 20, salary, 0)) as marketing_total,
   SUM(DECODE(department_id, 30, salary, 0)) as purchasing_total
FROM employees;

-- Performance considerations:
-- DECODE: Slightly faster in Oracle, Oracle-specific
-- CASE: SQL standard, more readable, supports complex conditions
-- Use CASE for complex logic, DECODE for simple value mapping in Oracle-only environments`
   },
   {
       id: 40,
       category: 'intermediate',
       difficulty: 'intermediate',
       question: 'How do you use Oracle analytical functions like LAG, LEAD, FIRST_VALUE, and LAST_VALUE?',
       answer: 'These analytical functions provide access to data from other rows in the result set without self-joins, useful for comparisons and trend analysis.',
       language: 'Oracle SQL',
       code: `-- LAG and LEAD for accessing previous and next rows
SELECT employee_id, hire_date, salary,
      LAG(salary, 1) OVER (ORDER BY hire_date) as prev_salary,
      LEAD(salary, 1) OVER (ORDER BY hire_date) as next_salary,
      salary - LAG(salary, 1) OVER (ORDER BY hire_date) as salary_diff_from_prev
FROM employees
ORDER BY hire_date;

-- LAG with default value and offset
SELECT employee_id, hire_date, salary,
      LAG(salary, 2, 0) OVER (ORDER BY hire_date) as salary_2_positions_back,
      LEAD(salary, 1, salary) OVER (ORDER BY hire_date) as next_salary_with_default
FROM employees;

-- FIRST_VALUE and LAST_VALUE with frames
SELECT employee_id, department_id, salary,
      FIRST_VALUE(salary) OVER (PARTITION BY department_id 
                               ORDER BY salary DESC 
                               ROWS UNBOUNDED PRECEDING) as highest_dept_salary,
      LAST_VALUE(salary) OVER (PARTITION BY department_id 
                              ORDER BY salary DESC 
                              ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING) as lowest_dept_salary
FROM employees;

-- Practical example: Sales trend analysis
SELECT month_year, sales_amount,
      LAG(sales_amount, 1) OVER (ORDER BY month_year) as prev_month_sales,
      LAG(sales_amount, 12) OVER (ORDER BY month_year) as same_month_last_year,
      
      -- Month-over-month growth
      ROUND(((sales_amount - LAG(sales_amount, 1) OVER (ORDER BY month_year)) / 
             LAG(sales_amount, 1) OVER (ORDER BY month_year)) * 100, 2) as mom_growth_pct,
      
      -- Year-over-year growth
      ROUND(((sales_amount - LAG(sales_amount, 12) OVER (ORDER BY month_year)) / 
             LAG(sales_amount, 12) OVER (ORDER BY month_year)) * 100, 2) as yoy_growth_pct,
      
      -- Running comparison with first month
      FIRST_VALUE(sales_amount) OVER (ORDER BY month_year 
                                     ROWS UNBOUNDED PRECEDING) as first_month_sales
FROM monthly_sales;

-- Advanced: Detecting salary changes
SELECT employee_id, effective_date, salary,
      LAG(salary) OVER (PARTITION BY employee_id ORDER BY effective_date) as prev_salary,
      CASE 
          WHEN LAG(salary) OVER (PARTITION BY employee_id ORDER BY effective_date) IS NULL THEN 'Initial'
          WHEN salary > LAG(salary) OVER (PARTITION BY employee_id ORDER BY effective_date) THEN 'Increase'
          WHEN salary < LAG(salary) OVER (PARTITION BY employee_id ORDER BY effective_date) THEN 'Decrease'
          ELSE 'No Change'
      END as salary_change_type
FROM salary_history;`
   },
   
   // PERFORMANCE TUNING (41-55)
   {
       id: 41,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you analyze and optimize Oracle SQL query execution plans?',
       answer: 'Use EXPLAIN PLAN, DBMS_XPLAN, and execution statistics to analyze query performance and identify optimization opportunities.',
       language: 'Oracle SQL',
       code: `-- Generate execution plan
EXPLAIN PLAN FOR
SELECT e.employee_id, e.first_name, e.last_name, d.department_name, e.salary
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.salary > 50000
ORDER BY e.salary DESC;

-- Display execution plan
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);

-- Display plan with additional details
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY(null, null, 'ALL'));

-- Real execution statistics (Oracle 10g+)
SELECT /*+ GATHER_PLAN_STATISTICS */ 
      e.employee_id, e.first_name, d.department_name, e.salary
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.salary > 50000;

-- Display actual execution statistics
SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY_CURSOR(null, null, 'ALLSTATS LAST'));

-- Analyze query performance with timing
SET TIMING ON
SET AUTOTRACE ON

SELECT e.employee_id, e.first_name, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.hire_date > DATE '2020-01-01';

-- Check for expensive operations in execution plan
SELECT sql_id, child_number, operation, options, cost, cardinality, bytes
FROM v$sql_plan
WHERE sql_id = '&sql_id'
ORDER BY id;

-- Optimization techniques based on plan analysis:

-- 1. Add missing indexes
CREATE INDEX idx_emp_salary ON employees(salary);
CREATE INDEX idx_emp_hire_date ON employees(hire_date);

-- 2. Use hints for specific optimization
SELECT /*+ USE_INDEX(e idx_emp_salary) */
      e.employee_id, e.salary
FROM employees e
WHERE e.salary > 50000;

-- 3. Rewrite subqueries as joins
-- Before (subquery)
SELECT * FROM employees 
WHERE department_id IN (SELECT department_id FROM departments WHERE location_id = 1700);

-- After (join)
SELECT e.* FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE d.location_id = 1700;

-- 4. Use EXISTS instead of IN for better performance
SELECT * FROM departments d
WHERE EXISTS (SELECT 1 FROM employees e WHERE e.department_id = d.department_id);

-- Monitor query performance
SELECT sql_text, executions, elapsed_time/1000000 as elapsed_seconds,
      cpu_time/1000000 as cpu_seconds, disk_reads, buffer_gets
FROM v$sql
WHERE sql_text LIKE '%your_query_pattern%'
ORDER BY elapsed_time DESC;`
   },
   {
       id: 42,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'What are Oracle hints and when should you use them for query optimization?',
       answer: 'Oracle hints are directives to the optimizer to influence execution plan generation. Use them carefully when the optimizer cannot determine the best plan.',
       language: 'Oracle SQL',
       code: `-- Index hints
SELECT /*+ INDEX(e emp_salary_idx) */ 
      employee_id, first_name, salary
FROM employees e
WHERE salary > 50000;

-- Use specific index
SELECT /*+ USE_INDEX(e, emp_dept_idx) */
      employee_id, department_id, salary
FROM employees e
WHERE department_id = 10;

-- Join hints
SELECT /*+ USE_HASH(e d) */
      e.employee_id, e.first_name, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id;

-- Nested loops hint (good for small result sets)
SELECT /*+ USE_NL(e d) */
      e.employee_id, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.employee_id = 100;

-- Merge join hint (good for sorted data)
SELECT /*+ USE_MERGE(e d) */
      e.employee_id, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id
ORDER BY e.employee_id;

-- Access method hints
SELECT /*+ FULL(e) */  -- Force full table scan
      employee_id, first_name, salary
FROM employees e
WHERE salary > 30000;

-- Parallel processing hints
SELECT /*+ PARALLEL(e, 4) */
      department_id, COUNT(*), AVG(salary)
FROM employees e
GROUP BY department_id;

-- First rows hint (optimize for fast first row return)
SELECT /*+ FIRST_ROWS(10) */
      employee_id, first_name, salary
FROM employees
ORDER BY salary DESC;

-- All rows hint (optimize for throughput)
SELECT /*+ ALL_ROWS */
      department_id, COUNT(*), SUM(salary)
FROM employees
GROUP BY department_id;

-- Multiple table hints
SELECT /*+ 
   USE_INDEX(e emp_dept_salary_idx)
   USE_HASH(e d)
   PARALLEL(e, 2)
*/
      e.employee_id, e.salary, d.department_name
FROM employees e
JOIN departments d ON e.department_id = d.department_id
WHERE e.salary > 60000;

-- Hints for specific scenarios:

-- Large table joins
SELECT /*+ USE_HASH(a b) PARALLEL(a, 4) PARALLEL(b, 4) */
      a.col1, b.col2
FROM large_table_a a
JOIN large_table_b b ON a.id = b.id;

-- Fact table to dimension table join
SELECT /*+ USE_NL(d f) INDEX(f fact_date_idx) */
      d.description, SUM(f.amount)
FROM dimension_table d
JOIN fact_table f ON d.id = f.dim_id
WHERE f.date_col > DATE '2024-01-01'
GROUP BY d.description;

-- When to use hints:
-- 1. Optimizer statistics are stale or missing
-- 2. Complex queries where optimizer chooses suboptimal plan
-- 3. Testing different execution strategies
-- 4. Time-critical queries needing consistent performance
-- 5. Data warehouse queries with known data patterns

-- Caution: Hints can become obsolete with data changes
-- Always test and monitor hint effectiveness over time`
   },
   {
       id: 43,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you optimize Oracle SQL queries for large datasets and data warehouses?',
       answer: 'Use partitioning, parallel processing, bitmap indexes, materialized views, and proper indexing strategies for optimal data warehouse performance.',


       language: 'Oracle SQL',
       code: `-- Partitioning strategies for large datasets
-- Range partitioning by date
CREATE TABLE sales_partitioned (
   sale_id NUMBER,
   sale_date DATE,
   customer_id NUMBER,
   amount NUMBER
)
PARTITION BY RANGE (sale_date) (
   PARTITION p_2023 VALUES LESS THAN (DATE '2024-01-01'),
   PARTITION p_2024 VALUES LESS THAN (DATE '2025-01-01'),
   PARTITION p_2025 VALUES LESS THAN (DATE '2026-01-01')
);

-- Hash partitioning for even distribution
CREATE TABLE customers_partitioned (
   customer_id NUMBER,
   customer_name VARCHAR2(100),
   region VARCHAR2(50)
)
PARTITION BY HASH (customer_id) PARTITIONS 8;

-- Parallel query execution
SELECT /*+ PARALLEL(s, 8) */
      EXTRACT(MONTH FROM sale_date) as month,
      SUM(amount) as total_sales
FROM sales_partitioned s
WHERE sale_date >= DATE '2024-01-01'
GROUP BY EXTRACT(MONTH FROM sale_date);

-- Bitmap indexes for low cardinality columns
CREATE BITMAP INDEX idx_sales_region ON sales_partitioned(region);
CREATE BITMAP INDEX idx_sales_status ON sales_partitioned(status);

-- Star transformation for data warehouse queries
SELECT /*+ STAR_TRANSFORMATION */
      d.region, p.category, t.quarter,
      SUM(f.sales_amount) as total_sales
FROM fact_sales f
JOIN dim_customer d ON f.customer_id = d.customer_id
JOIN dim_product p ON f.product_id = p.product_id
JOIN dim_time t ON f.time_id = t.time_id
WHERE d.region = 'North America'
 AND p.category = 'Electronics'
 AND t.year = 2024
GROUP BY d.region, p.category, t.quarter;

-- Materialized views for pre-aggregated data
CREATE MATERIALIZED VIEW mv_monthly_sales
BUILD IMMEDIATE
REFRESH FAST ON COMMIT
AS
SELECT TRUNC(sale_date, 'MM') as month,
      region,
      SUM(amount) as total_amount,
      COUNT(*) as transaction_count
FROM sales_partitioned
GROUP BY TRUNC(sale_date, 'MM'), region;

-- Query rewrite using materialized view
SELECT month, region, total_amount
FROM mv_monthly_sales
WHERE month >= DATE '2024-01-01';

-- Bulk operations for large data loads
INSERT /*+ APPEND */ INTO target_table
SELECT * FROM source_table
WHERE condition;

-- Parallel DML operations
ALTER SESSION ENABLE PARALLEL DML;
UPDATE /*+ PARALLEL(sales, 4) */ sales 
SET status = 'PROCESSED'
WHERE sale_date < ADD_MONTHS(SYSDATE, -12);

-- Index optimization for data warehouse
-- Compressed indexes to save space
CREATE INDEX idx_sales_compressed ON sales_partitioned(customer_id, sale_date)
COMPRESS 2;

-- Function-based indexes for common calculations
CREATE INDEX idx_sales_year ON sales_partitioned(EXTRACT(YEAR FROM sale_date));

-- Query optimization techniques
-- Use CASE instead of multiple queries
SELECT customer_id,
      SUM(CASE WHEN status = 'COMPLETED' THEN amount ELSE 0 END) as completed_sales,
      SUM(CASE WHEN status = 'PENDING' THEN amount ELSE 0 END) as pending_sales,
      SUM(CASE WHEN status = 'CANCELLED' THEN amount ELSE 0 END) as cancelled_sales
FROM sales_partitioned
GROUP BY customer_id;

-- Eliminate unnecessary sorting
SELECT customer_id, SUM(amount)
FROM sales_partitioned
WHERE sale_date >= DATE '2024-01-01'
GROUP BY customer_id;  -- No ORDER BY unless needed

-- Use analytical functions instead of self-joins
SELECT sale_id, amount,
      SUM(amount) OVER (PARTITION BY customer_id) as customer_total,
      RANK() OVER (PARTITION BY customer_id ORDER BY amount DESC) as amount_rank
FROM sales_partitioned;`
   },
   {
       id: 44,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement row-level security and data masking in Oracle SQL?',
       answer: 'Oracle provides Virtual Private Database (VPD), Row Level Security (RLS), and data masking features to control data access and protect sensitive information.',
       language: 'Oracle SQL',
       code: `-- Virtual Private Database (VPD) Policy
-- Create security function
CREATE OR REPLACE FUNCTION emp_security_policy(
   schema_var IN VARCHAR2,
   table_var IN VARCHAR2
) RETURN VARCHAR2 AS
   v_predicate VARCHAR2(400);
BEGIN
   -- Users can only see their own records or their subordinates
   IF USER = 'HR_MANAGER' THEN
       v_predicate := '1=1';  -- HR Manager sees all
   ELSIF USER = 'DEPARTMENT_MANAGER' THEN
       v_predicate := 'department_id IN (SELECT department_id FROM user_departments WHERE username = USER)';
   ELSE
       v_predicate := 'employee_id = (SELECT employee_id FROM employees WHERE username = USER)';
   END IF;
   
   RETURN v_predicate;
END;
/

-- Apply VPD policy
BEGIN
   DBMS_RLS.ADD_POLICY(
       object_schema => 'HR',
       object_name => 'EMPLOYEES',
       policy_name => 'EMP_SECURITY_POLICY',
       function_schema => 'HR',
       policy_function => 'EMP_SECURITY_POLICY',
       statement_types => 'SELECT,INSERT,UPDATE,DELETE'
   );
END;
/

-- Row Level Security (Oracle 12c+)
-- Create security predicate function
CREATE OR REPLACE FUNCTION sales_security_predicate(
   p_schema VARCHAR2,
   p_object VARCHAR2
) RETURN VARCHAR2 IS
BEGIN
   RETURN 'region = SYS_CONTEXT(''USERENV'', ''CLIENT_IDENTIFIER'')';
END;
/

-- Enable RLS on table
ALTER TABLE sales ENABLE ROW LEVEL SECURITY;

-- Add RLS policy
BEGIN
   DBMS_RLS.ADD_POLICY(
       object_schema => USER,
       object_name => 'SALES',
       policy_name => 'SALES_RLS_POLICY',
       policy_function => 'SALES_SECURITY_PREDICATE',
       statement_types => 'SELECT'
   );
END;
/

-- Data masking for sensitive columns
-- Create masking function
CREATE OR REPLACE FUNCTION mask_ssn(p_ssn VARCHAR2) RETURN VARCHAR2 IS
BEGIN
   RETURN 'XXX-XX-' || SUBSTR(p_ssn, -4);
END;
/

-- Apply masking in queries
SELECT employee_id,
      first_name,
      last_name,
      CASE 
          WHEN USER IN ('HR_ADMIN', 'PAYROLL_ADMIN') THEN ssn
          ELSE mask_ssn(ssn)
      END as ssn,
      CASE 
          WHEN USER IN ('HR_ADMIN', 'MANAGER') THEN salary
          ELSE NULL
      END as salary
FROM employees;

-- Column-level security using views
CREATE VIEW employees_public AS
SELECT employee_id,
      first_name,
      last_name,
      department_id,
      hire_date,
      -- Mask email domain
      SUBSTR(email, 1, INSTR(email, '@') - 1) || '@*****.com' as email,
      -- Salary ranges instead of exact amounts
      CASE 
          WHEN salary < 30000 THEN 'Low'
          WHEN salary < 60000 THEN 'Medium'
          WHEN salary < 100000 THEN 'High'
          ELSE 'Executive'
      END as salary_range
FROM employees
WHERE department_id IN (SELECT department_id FROM user_accessible_departments WHERE username = USER);

-- Context-based security
-- Set application context
BEGIN
   DBMS_SESSION.SET_CONTEXT(
       namespace => 'USER_SECURITY',
       attribute => 'DEPARTMENT_ID',
       value => '10'
   );
END;
/

-- Use context in security policy
CREATE OR REPLACE FUNCTION context_security_policy(
   schema_var IN VARCHAR2,
   table_var IN VARCHAR2
) RETURN VARCHAR2 AS
BEGIN
   RETURN 'department_id = SYS_CONTEXT(''USER_SECURITY'', ''DEPARTMENT_ID'')';
END;
/

-- Dynamic data masking (Oracle 12c+)
ALTER TABLE employees MODIFY (ssn VARCHAR2(11) 
   DEFAULT ON NULL SYS_GUID() 
   ENCRYPT USING 'AES128' 
   IDENTIFIED BY "encryption_key"
);

-- Audit sensitive data access
AUDIT SELECT ON employees BY ACCESS;
AUDIT UPDATE ON employees BY ACCESS;

-- Check audit trail
SELECT username, obj_name, action_name, timestamp
FROM dba_audit_trail
WHERE obj_name = 'EMPLOYEES'
ORDER BY timestamp DESC;`
   },

   // COMPLEX SCENARIOS (45-60)
   {
       id: 45,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement complex business logic using Oracle SQL for inventory management?',
       answer: 'Use advanced SQL techniques including CTEs, window functions, and MERGE statements to handle complex inventory calculations, stock movements, and reorder logic.',
       language: 'Oracle SQL',
       code: `-- Complex inventory management with FIFO (First In, First Out)
WITH inventory_movements AS (
   SELECT product_id, movement_date, movement_type, quantity, unit_cost,
          SUM(CASE WHEN movement_type = 'IN' THEN quantity ELSE -quantity END) 
          OVER (PARTITION BY product_id ORDER BY movement_date, movement_id
                ROWS UNBOUNDED PRECEDING) as running_balance
   FROM stock_movements
),
current_stock AS (
   SELECT product_id,
          SUM(CASE WHEN movement_type = 'IN' THEN quantity ELSE -quantity END) as current_quantity,
          AVG(CASE WHEN movement_type = 'IN' THEN unit_cost END) as avg_cost
   FROM stock_movements
   GROUP BY product_id
),
reorder_analysis AS (
   SELECT p.product_id, p.product_name, p.reorder_level, p.reorder_quantity,
          cs.current_quantity, cs.avg_cost,
          CASE 
              WHEN cs.current_quantity <= p.reorder_level THEN 'REORDER_NEEDED'
              WHEN cs.current_quantity <= p.reorder_level * 1.2 THEN 'LOW_STOCK'
              ELSE 'ADEQUATE'
          END as stock_status,
          -- Calculate economic order quantity
          SQRT((2 * p.annual_demand * p.ordering_cost) / p.holding_cost_rate) as eoq
   FROM products p
   LEFT JOIN current_stock cs ON p.product_id = cs.product_id
)
SELECT product_id, product_name, current_quantity, reorder_level, stock_status,
      CASE WHEN stock_status = 'REORDER_NEEDED' 
           THEN GREATEST(reorder_quantity, CEIL(eoq))
           ELSE 0 
      END as suggested_order_quantity,
      avg_cost * CASE WHEN stock_status = 'REORDER_NEEDED' 
                      THEN GREATEST(reorder_quantity, CEIL(eoq))
                      ELSE 0 END as estimated_order_cost
FROM reorder_analysis
ORDER BY 
   CASE stock_status 
       WHEN 'REORDER_NEEDED' THEN 1
       WHEN 'LOW_STOCK' THEN 2
       ELSE 3
   END,
   current_quantity;

-- Advanced stock allocation with priority customers
WITH customer_orders AS (
   SELECT order_id, customer_id, product_id, order_quantity, order_date, priority_level,
          ROW_NUMBER() OVER (PARTITION BY product_id 
                            ORDER BY priority_level DESC, order_date) as allocation_order
   FROM sales_orders
   WHERE order_status = 'PENDING'
),
available_stock AS (
   SELECT product_id, 
          SUM(CASE WHEN movement_type = 'IN' THEN quantity ELSE -quantity END) as available_qty
   FROM stock_movements
   GROUP BY product_id
),
stock_allocation AS (
   SELECT co.order_id, co.customer_id, co.product_id, co.order_quantity,
          ast.available_qty,
          SUM(co.order_quantity) OVER (PARTITION BY co.product_id 
                                      ORDER BY co.allocation_order
                                      ROWS UNBOUNDED PRECEDING) as cumulative_demand,
          CASE 
              WHEN SUM(co.order_quantity) OVER (PARTITION BY co.product_id 
                                               ORDER BY co.allocation_order
                                               ROWS UNBOUNDED PRECEDING) <= ast.available_qty 
              THEN co.order_quantity
              WHEN LAG(SUM(co.order_quantity) OVER (PARTITION BY co.product_id 
                                                   ORDER BY co.allocation_order
                                                   ROWS UNBOUNDED PRECEDING), 1, 0) 
                   OVER (PARTITION BY co.product_id ORDER BY co.allocation_order) < ast.available_qty
              THEN ast.available_qty - LAG(SUM(co.order_quantity) OVER (PARTITION BY co.product_id 
                                                                       ORDER BY co.allocation_order
                                                                       ROWS UNBOUNDED PRECEDING), 1, 0) 
                   OVER (PARTITION BY co.product_id ORDER BY co.allocation_order)
              ELSE 0
          END as allocated_quantity
   FROM customer_orders co
   JOIN available_stock ast ON co.product_id = ast.product_id
)
SELECT order_id, customer_id, product_id, order_quantity, allocated_quantity,
      order_quantity - allocated_quantity as backorder_quantity,
      CASE 
          WHEN allocated_quantity = order_quantity THEN 'FULLY_ALLOCATED'
          WHEN allocated_quantity > 0 THEN 'PARTIALLY_ALLOCATED'
          ELSE 'BACKORDERED'
      END as allocation_status
FROM stock_allocation;

-- Inventory aging analysis
WITH inventory_aging AS (
   SELECT product_id, movement_date, quantity, unit_cost,
          CASE 
              WHEN SYSDATE - movement_date <= 30 THEN '0-30 days'
              WHEN SYSDATE - movement_date <= 60 THEN '31-60 days'
              WHEN SYSDATE - movement_date <= 90 THEN '61-90 days'
              WHEN SYSDATE - movement_date <= 180 THEN '91-180 days'
              ELSE 'Over 180 days'
          END as age_category,
          quantity * unit_cost as inventory_value
   FROM stock_movements
   WHERE movement_type = 'IN'
     AND quantity > 0  -- Only positive inventory
)
SELECT product_id, age_category,
      SUM(quantity) as total_quantity,
      SUM(inventory_value) as total_value,
      ROUND(SUM(inventory_value) / SUM(SUM(inventory_value)) OVER (PARTITION BY product_id) * 100, 2) as pct_of_total_value
FROM inventory_aging
GROUP BY product_id, age_category
ORDER BY product_id, 
        CASE age_category
            WHEN '0-30 days' THEN 1
            WHEN '31-60 days' THEN 2
            WHEN '61-90 days' THEN 3
            WHEN '91-180 days' THEN 4
            ELSE 5
        END;`
   },
   {
       id: 46,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you handle complex financial calculations and period-over-period analysis in Oracle SQL?',
       answer: 'Use window functions, CTEs, and Oracle date functions to perform complex financial analysis including YoY growth, moving averages, and variance analysis.',
       language: 'Oracle SQL',
       code: `-- Comprehensive financial analysis with period comparisons
WITH monthly_financials AS (
   SELECT TRUNC(transaction_date, 'MM') as month,
          account_category,
          SUM(CASE WHEN transaction_type = 'CREDIT' THEN amount ELSE -amount END) as net_amount
   FROM financial_transactions
   WHERE transaction_date >= ADD_MONTHS(TRUNC(SYSDATE, 'MM'), -24)
   GROUP BY TRUNC(transaction_date, 'MM'), account_category
),
financial_metrics AS (
   SELECT month, account_category, net_amount,
          -- Previous month comparison
          LAG(net_amount, 1) OVER (PARTITION BY account_category ORDER BY month) as prev_month,
          -- Same month last year
          LAG(net_amount, 12) OVER (PARTITION BY account_category ORDER BY month) as same_month_ly,
          -- 3-month moving average
          AVG(net_amount) OVER (PARTITION BY account_category 
                               ORDER BY month 
                               ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) as moving_avg_3m,
          -- Year-to-date calculation
          SUM(net_amount) OVER (PARTITION BY account_category, EXTRACT(YEAR FROM month) 
                               ORDER BY month 
                               ROWS UNBOUNDED PRECEDING) as ytd_amount,
          -- Rolling 12-month total
          SUM(net_amount) OVER (PARTITION BY account_category 
                               ORDER BY month 
                               ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) as rolling_12m
   FROM monthly_financials
)
SELECT month, account_category, net_amount,
      prev_month, same_month_ly,
      
      -- Month-over-month growth
      ROUND(((net_amount - prev_month) / NULLIF(ABS(prev_month), 0)) * 100, 2) as mom_growth_pct,
      
      -- Year-over-year growth
      ROUND(((net_amount - same_month_ly) / NULLIF(ABS(same_month_ly), 0)) * 100, 2) as yoy_growth_pct,
      
      -- Variance from moving average
      ROUND(net_amount - moving_avg_3m, 2) as variance_from_avg,
      ROUND(((net_amount - moving_avg_3m) / NULLIF(ABS(moving_avg_3m), 0)) * 100, 2) as variance_pct,
      
      ytd_amount, rolling_12m,
      
      -- Trend analysis
      CASE 
          WHEN net_amount > LAG(net_amount, 1) OVER (PARTITION BY account_category ORDER BY month) 
           AND LAG(net_amount, 1) OVER (PARTITION BY account_category ORDER BY month) > 
               LAG(net_amount, 2) OVER (PARTITION BY account_category ORDER BY month)
          THEN 'UPWARD_TREND'
          WHEN net_amount < LAG(net_amount, 1) OVER (PARTITION BY account_category ORDER BY month) 
           AND LAG(net_amount, 1) OVER (PARTITION BY account_category ORDER BY month) < 
               LAG(net_amount, 2) OVER (PARTITION BY account_category ORDER BY month)
          THEN 'DOWNWARD_TREND'
          ELSE 'STABLE'
      END as trend_indicator
FROM financial_metrics
WHERE month >= ADD_MONTHS(TRUNC(SYSDATE, 'MM'), -12)
ORDER BY account_category, month;

-- Complex revenue recognition with deferred revenue
WITH contract_revenue AS (
   SELECT contract_id, contract_start_date, contract_end_date, total_contract_value,
          MONTHS_BETWEEN(contract_end_date, contract_start_date) as contract_months,
          total_contract_value / MONTHS_BETWEEN(contract_end_date, contract_start_date) as monthly_revenue
   FROM contracts
   WHERE contract_status = 'ACTIVE'
),
revenue_schedule AS (
   SELECT contract_id, total_contract_value, monthly_revenue,
          ADD_MONTHS(contract_start_date, LEVEL - 1) as revenue_month,
          CASE 
              WHEN ADD_MONTHS(contract_start_date, LEVEL - 1) <= TRUNC(SYSDATE, 'MM') 
              THEN monthly_revenue 
              ELSE 0 
          END as recognized_revenue,
          CASE 
              WHEN ADD_MONTHS(contract_start_date, LEVEL - 1) > TRUNC(SYSDATE, 'MM') 
              THEN monthly_revenue 
              ELSE 0 
          END as deferred_revenue
   FROM contract_revenue
   CONNECT BY LEVEL <= contract_months 
          AND PRIOR contract_id = contract_id 
          AND PRIOR SYS_GUID() IS NOT NULL
)
SELECT revenue_month,
      SUM(recognized_revenue) as total_recognized,
      SUM(deferred_revenue) as total_deferred,
      SUM(monthly_revenue) as total_scheduled,
      -- Cumulative recognized revenue
      SUM(SUM(recognized_revenue)) OVER (ORDER BY revenue_month) as cumulative_recognized
FROM revenue_schedule
GROUP BY revenue_month
ORDER BY revenue_month;

-- Financial ratios and KPI calculations
WITH financial_summary AS (
   SELECT EXTRACT(YEAR FROM transaction_date) as fiscal_year,
          SUM(CASE WHEN account_type = 'REVENUE' THEN amount ELSE 0 END) as total_revenue,
          SUM(CASE WHEN account_type = 'COST_OF_SALES' THEN amount ELSE 0 END) as cost_of_sales,
          SUM(CASE WHEN account_type = 'OPERATING_EXPENSE' THEN amount ELSE 0 END) as operating_expenses,
          SUM(CASE WHEN account_type = 'CURRENT_ASSET' THEN amount ELSE 0 END) as current_assets,
          SUM(CASE WHEN account_type = 'CURRENT_LIABILITY' THEN amount ELSE 0 END) as current_liabilities,
          SUM(CASE WHEN account_type = 'TOTAL_ASSET' THEN amount ELSE 0 END) as total_assets,
          SUM(CASE WHEN account_type = 'TOTAL_EQUITY' THEN amount ELSE 0 END) as total_equity
   FROM financial_transactions
   GROUP BY EXTRACT(YEAR FROM transaction_date)
)
SELECT fiscal_year,
      total_revenue,
      cost_of_sales,
      operating_expenses,
      total_revenue - cost_of_sales as gross_profit,
      ROUND((total_revenue - cost_of_sales) / NULLIF(total_revenue, 0) * 100, 2) as gross_margin_pct,
      total_revenue - cost_of_sales - operating_expenses as operating_income,
      ROUND((total_revenue - cost_of_sales - operating_expenses) / NULLIF(total_revenue, 0) * 100, 2) as operating_margin_pct,
      -- Financial ratios
      ROUND(current_assets / NULLIF(current_liabilities, 0), 2) as current_ratio,
      ROUND(total_equity / NULLIF(total_assets, 0) * 100, 2) as equity_ratio_pct,
      -- Year-over-year growth
      LAG(total_revenue) OVER (ORDER BY fiscal_year) as prev_year_revenue,
      ROUND(((total_revenue - LAG(total_revenue) OVER (ORDER BY fiscal_year)) / 
             NULLIF(LAG(total_revenue) OVER (ORDER BY fiscal_year), 0)) * 100, 2) as revenue_growth_pct
FROM financial_summary
ORDER BY fiscal_year;`
   },
   {
       id: 47,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement data quality checks and validation rules in Oracle SQL?',
       answer: 'Use constraints, check conditions, analytical functions, and custom validation logic to ensure data integrity and identify data quality issues.',
       language: 'Oracle SQL',
       code: `-- Comprehensive data quality validation framework
WITH data_quality_checks AS (
   -- Check for missing required fields
   SELECT 'MISSING_VALUES' as check_type,
          'employee_id' as column_name,
          COUNT(*) as issue_count,
          'Employee ID cannot be null' as description
   FROM employees 
   WHERE employee_id IS NULL
   
   UNION ALL
   
   SELECT 'MISSING_VALUES',
          'email',
          COUNT(*),
          'Email address is required'
   FROM employees 
   WHERE email IS NULL OR TRIM(email) = ''
   
   UNION ALL
   
   -- Check for invalid email formats
   SELECT 'INVALID_FORMAT',
          'email',
          COUNT(*),
          'Invalid email format'
   FROM employees 
   WHERE email IS NOT NULL 
     AND NOT REGEXP_LIKE(email, '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$')
   
   UNION ALL
   
   -- Check for duplicate values
   SELECT 'DUPLICATES',
          'email',
          COUNT(*) - COUNT(DISTINCT email),
          'Duplicate email addresses found'
   FROM employees 
   WHERE email IS NOT NULL
   
   UNION ALL
   
   -- Check for referential integrity
   SELECT 'ORPHANED_RECORDS',
          'department_id',
          COUNT(*),
          'Employees with invalid department references'
   FROM employees e
   LEFT JOIN departments d ON e.department_id = d.department_id
   WHERE e.department_id IS NOT NULL AND d.department_id IS NULL
   
   UNION ALL
   
   -- Check for invalid date ranges
   SELECT 'INVALID_DATE_RANGE',
          'hire_date',
          COUNT(*),
          'Hire date cannot be in the future'
   FROM employees 
   WHERE hire_date > SYSDATE
   
   UNION ALL
   
   -- Check for logical inconsistencies
   SELECT 'LOGICAL_INCONSISTENCY',
          'salary_vs_job',
          COUNT(*),
          'Salary outside expected range for job level'
   FROM employees e
   JOIN jobs j ON e.job_id = j.job_id
   WHERE e.salary NOT BETWEEN j.min_salary AND j.max_salary
),
data_completeness AS (
   SELECT 'COMPLETENESS_CHECK' as check_type,
          column_name,
          total_records,
          non_null_records,
          ROUND((non_null_records / total_records) * 100, 2) as completeness_pct
   FROM (
       SELECT 'first_name' as column_name,
              COUNT(*) as total_records,
              COUNT(first_name) as non_null_records
       FROM employees
       UNION ALL
       SELECT 'last_name',
              COUNT(*),
              COUNT(last_name)
       FROM employees
       UNION ALL
       SELECT 'email',
              COUNT(*),
              COUNT(email)
       FROM employees
       UNION ALL
       SELECT 'phone_number',
              COUNT(*),
              COUNT(phone_number)
       FROM employees
   )
)
-- Combine all quality checks
SELECT check_type, column_name, 
      CASE 
          WHEN check_type = 'COMPLETENESS_CHECK' 
          THEN CAST(completeness_pct AS NUMBER)
          ELSE issue_count 
      END as metric_value,
      CASE 
          WHEN check_type = 'COMPLETENESS_CHECK' 
          THEN 'Completeness: ' || completeness_pct || '%'
          ELSE description 
      END as description,
      CASE 
          WHEN check_type = 'COMPLETENESS_CHECK' AND completeness_pct < 95 THEN 'HIGH'
          WHEN check_type != 'COMPLETENESS_CHECK' AND metric_value > 0 THEN 'HIGH'
          WHEN check_type = 'COMPLETENESS_CHECK' AND completeness_pct < 99 THEN 'MEDIUM'
          ELSE 'LOW'
      END as severity
FROM (
   SELECT check_type, column_name, issue_count, description, NULL as completeness_pct, NULL as total_records, NULL as non_null_records
   FROM data_quality_checks
   WHERE issue_count > 0
   UNION ALL
   SELECT check_type, column_name, NULL, NULL, completeness_pct, total_records, non_null_records
   FROM data_completeness
)
ORDER BY 
   CASE severity WHEN 'HIGH' THEN 1 WHEN 'MEDIUM' THEN 2 ELSE 3 END,
   check_type, column_name;

-- Advanced outlier detection
WITH statistical_analysis AS (
   SELECT department_id,
          AVG(salary) as mean_salary,
          STDDEV(salary) as stddev_salary,
          PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY salary) as q1,
          PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY salary) as q3,
          PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY salary) - 
          PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY salary) as iqr
   FROM employees
   GROUP BY department_id
),
outlier_detection AS (
   SELECT e.employee_id, e.first_name, e.last_name, e.salary, e.department_id,
          s.mean_salary, s.stddev_salary, s.q1, s.q3, s.iqr,
          -- Z-score method
          ABS((e.salary - s.mean_salary) / NULLIF(s.stddev_salary, 0)) as z_score,
          -- IQR method
          CASE 
              WHEN e.salary < (s.q1 - 1.5 * s.iqr) OR e.salary > (s.q3 + 1.5 * s.iqr) 
              THEN 'IQR_OUTLIER'
              ELSE 'NORMAL'
          END as iqr_status,
          -- Statistical outlier
          CASE 
              WHEN ABS((e.salary - s.mean_salary) / NULLIF(s.stddev_salary, 0)) > 2 
              THEN 'STATISTICAL_OUTLIER'
              ELSE 'NORMAL'
          END as statistical_status
   FROM employees e
   JOIN statistical_analysis s ON e.department_id = s.department_id
)
SELECT employee_id, first_name, last_name, salary, department_id,
      ROUND(z_score, 2) as z_score,
      iqr_status,
      statistical_status,
      CASE 
          WHEN iqr_status = 'IQR_OUTLIER' AND statistical_status = 'STATISTICAL_OUTLIER' 
          THEN 'STRONG_OUTLIER'
          WHEN iqr_status = 'IQR_OUTLIER' OR statistical_status = 'STATISTICAL_OUTLIER' 
          THEN 'POTENTIAL_OUTLIER'
          ELSE 'NORMAL'
      END as outlier_classification
FROM outlier_detection
WHERE iqr_status = 'IQR_OUTLIER' OR statistical_status = 'STATISTICAL_OUTLIER'
ORDER BY z_score DESC;

-- Data consistency validation across related tables
SELECT 
   'CONSISTENCY_CHECK' as validation_type,
   'Employee-Department Totals' as check_description,
   emp_count_from_emp_table,
   emp_count_from_dept_table,
   ABS(emp_count_from_emp_table - emp_count_from_dept_table) as discrepancy,
   CASE 
       WHEN emp_count_from_emp_table = emp_count_from_dept_table THEN 'CONSISTENT'
       ELSE 'INCONSISTENT'
   END as status
FROM (
   SELECT 
       (SELECT COUNT(*) FROM employees WHERE department_id IS NOT NULL) as emp_count_from_emp_table,
       (SELECT SUM(employee_count) FROM departments WHERE employee_count IS NOT NULL) as emp_count_from_dept_table
   FROM dual
)

UNION ALL

-- Validate salary ranges against job definitions
SELECT 
   'BUSINESS_RULE_VALIDATION',
   'Salary Range Compliance',
   COUNT(*) as violations_found,
   0 as expected_violations,
   COUNT(*) as discrepancy,
   CASE WHEN COUNT(*) = 0 THEN 'COMPLIANT' ELSE 'NON_COMPLIANT' END
FROM employees e
JOIN jobs j ON e.job_id = j.job_id
WHERE e.salary < j.min_salary * 0.8 OR e.salary > j.max_salary * 1.2;`
   },
   
   // ADVANCED ORACLE FEATURES (48-65)
   {
       id: 48,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you use Oracle PIVOT and UNPIVOT operations for data transformation?',
       answer: 'PIVOT transforms rows into columns while UNPIVOT does the reverse. These operations are useful for data analysis and reporting transformations.',
       language: 'Oracle SQL',
       code: `-- Sample data setup
CREATE TABLE quarterly_sales AS
SELECT 'John' as salesperson, 'Q1' as quarter, 10000 as sales_amount FROM dual UNION ALL
SELECT 'John', 'Q2', 15000 FROM dual UNION ALL
SELECT 'John', 'Q3', 12000 FROM dual UNION ALL
SELECT 'John', 'Q4', 18000 FROM dual UNION ALL
SELECT 'Mary', 'Q1', 12000 FROM dual UNION ALL
SELECT 'Mary', 'Q2', 14000 FROM dual UNION ALL
SELECT 'Mary', 'Q3', 16000 FROM dual UNION ALL
SELECT 'Mary', 'Q4', 20000 FROM dual;

-- PIVOT: Transform quarters from rows to columns
SELECT * FROM (
   SELECT salesperson, quarter, sales_amount
   FROM quarterly_sales
)
PIVOT (
   SUM(sales_amount)
   FOR quarter IN ('Q1' as Q1, 'Q2' as Q2, 'Q3' as Q3, 'Q4' as Q4)
);

-- Advanced PIVOT with multiple aggregations
SELECT * FROM (
   SELECT salesperson, quarter, sales_amount
   FROM quarterly_sales
)
PIVOT (
   SUM(sales_amount) as total,
   AVG(sales_amount) as average,
   COUNT(*) as count_quarters
   FOR quarter IN ('Q1', 'Q2', 'Q3', 'Q4')
);

-- Dynamic PIVOT using XML
SELECT salesperson,
      EXTRACTVALUE(quarterly_data, '/PivotSet/item[@quarter="Q1"]/@sales') as Q1,
      EXTRACTVALUE(quarterly_data, '/PivotSet/item[@quarter="Q2"]/@sales') as Q2,
      EXTRACTVALUE(quarterly_data, '/PivotSet/item[@quarter="Q3"]/@sales') as Q3,
      EXTRACTVALUE(quarterly_data, '/PivotSet/item[@quarter="Q4"]/@sales') as Q4
FROM (
   SELECT salesperson,
          XMLAGG(XMLELEMENT("item", 
                           XMLATTRIBUTES(quarter as "quarter", sales_amount as "sales")
                           ) ORDER BY quarter).getClobVal() as quarterly_data
   FROM quarterly_sales
   GROUP BY salesperson
);

-- UNPIVOT: Transform columns back to rows
WITH pivoted_data AS (
   SELECT 'John' as salesperson, 10000 as Q1, 15000 as Q2, 12000 as Q3, 18000 as Q4 FROM dual
   UNION ALL
   SELECT 'Mary', 12000, 14000, 16000, 20000 FROM dual
)
SELECT salesperson, quarter, sales_amount
FROM pivoted_data
UNPIVOT (
   sales_amount FOR quarter IN (Q1, Q2, Q3, Q4)
);

-- Complex PIVOT for financial reporting
WITH financial_data AS (
   SELECT 'Revenue' as account_type, 'Jan' as month, 100000 as amount FROM dual UNION ALL
   SELECT 'Revenue', 'Feb', 120000 FROM dual UNION ALL
   SELECT 'Revenue', 'Mar', 110000 FROM dual UNION ALL
   SELECT 'Expenses', 'Jan', 80000 FROM dual UNION ALL
   SELECT 'Expenses', 'Feb', 85000 FROM dual UNION ALL
   SELECT 'Expenses', 'Mar', 90000 FROM dual
)
SELECT account_type,
      NVL(Jan, 0) as Jan,
      NVL(Feb, 0) as Feb,
      NVL(Mar, 0) as Mar,
      NVL(Jan, 0) + NVL(Feb, 0) + NVL(Mar, 0) as Total
FROM (
   SELECT account_type, month, amount
   FROM financial_data
)
PIVOT (
   SUM(amount)
   FOR month IN ('Jan' as Jan, 'Feb' as Feb, 'Mar' as Mar)
)
ORDER BY account_type;

-- PIVOT with calculated columns
SELECT * FROM (
   SELECT salesperson, quarter, sales_amount,
          CASE 
              WHEN quarter = 'Q1' THEN 'First_Half'
              WHEN quarter = 'Q2' THEN 'First_Half'
              WHEN quarter = 'Q3' THEN 'Second_Half'
              WHEN quarter = 'Q4' THEN 'Second_Half'
          END as half_year
   FROM quarterly_sales
)
PIVOT (
   SUM(sales_amount)
   FOR half_year IN ('First_Half' as H1, 'Second_Half' as H2)
);

-- UNPIVOT with multiple value columns
WITH multi_metric_data AS (
   SELECT 'Product_A' as product, 1000 as units_sold, 50000 as revenue FROM dual
   UNION ALL
   SELECT 'Product_B', 800, 40000 FROM dual
   UNION ALL
   SELECT 'Product_C', 1200, 60000 FROM dual
)
SELECT product, metric_type, metric_value
FROM multi_metric_data
UNPIVOT (
   metric_value FOR metric_type IN (units_sold as 'Units', revenue as 'Revenue')
);

-- Cleanup
DROP TABLE quarterly_sales;`
   },
   {
       id: 49,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement Oracle Flashback features for data recovery and historical analysis?',
       answer: 'Oracle Flashback provides multiple features for viewing and recovering data as it existed at previous points in time, including Flashback Query, Flashback Table, and Flashback Database.',
       language: 'Oracle SQL',
       code: `-- Enable Flashback Archive (requires DBA privileges)
CREATE FLASHBACK ARCHIVE fla_employees 
TABLESPACE flashback_ts 
RETENTION 1 YEAR;

-- Enable flashback archiving on table
ALTER TABLE employees FLASHBACK ARCHIVE fla_employees;

-- Flashback Query - View data as it was at specific time
SELECT employee_id, first_name, last_name, salary
FROM employees
AS OF TIMESTAMP (SYSTIMESTAMP - INTERVAL '1' HOUR)
WHERE department_id = 10;

-- Flashback Query using SCN (System Change Number)
SELECT employee_id, first_name, salary
FROM employees
AS OF SCN 1234567
WHERE employee_id = 100;

-- Compare current data with historical data
SELECT 'CURRENT' as data_version, employee_id, first_name, salary FROM employees WHERE employee_id = 100
UNION ALL
SELECT 'YESTERDAY' as data_version, employee_id, first_name, salary 
FROM employees AS OF TIMESTAMP (SYSTIMESTAMP - INTERVAL '1' DAY)
WHERE employee_id = 100;

-- Find when data was changed using Flashback Version Query
SELECT employee_id, first_name, salary, 
      versions_starttime, versions_endtime, versions_operation,
      versions_xid as transaction_id
FROM employees 
VERSIONS BETWEEN TIMESTAMP 
   (SYSTIMESTAMP - INTERVAL '7' DAY) AND SYSTIMESTAMP
WHERE employee_id = 100;

-- Flashback Transaction Query to see what changed
SELECT operation, undo_sql, table_name, table_owner, timestamp
FROM flashback_transaction_query
WHERE xid = '0600030015000000';

-- Recover accidentally deleted data
-- Step 1: Find when data was deleted
SELECT employee_id, first_name, versions_operation, versions_starttime
FROM employees 
VERSIONS BETWEEN TIMESTAMP 
   (SYSTIMESTAMP - INTERVAL '1' DAY) AND SYSTIMESTAMP
WHERE employee_id = 999  -- Assuming this employee was deleted
 AND versions_operation = 'D';

-- Step 2: Recover the deleted data
INSERT INTO employees
SELECT employee_id, first_name, last_name, email, phone_number, 
      hire_date, job_id, salary, commission_pct, manager_id, department_id
FROM employees
AS OF TIMESTAMP (TIMESTAMP '2024-01-15 14:30:00')
WHERE employee_id = 999;

-- Flashback Table to restore entire table
FLASHBACK TABLE employees TO TIMESTAMP 
   (SYSTIMESTAMP - INTERVAL '2' HOUR);

-- Alternative: Flashback Table using SCN
FLASHBACK TABLE employees TO SCN 1234567;

-- Create a point-in-time copy of table for analysis
CREATE TABLE employees_snapshot AS
SELECT * FROM employees
AS OF TIMESTAMP (SYSTIMESTAMP - INTERVAL '1' DAY);

-- Historical trend analysis using Flashback
WITH historical_snapshots AS (
   SELECT 'CURRENT' as snapshot_date, department_id, COUNT(*) as emp_count, AVG(salary) as avg_salary
   FROM employees GROUP BY department_id
   UNION ALL
   SELECT 'LAST_MONTH', department_id, COUNT(*), AVG(salary)
   FROM employees AS OF TIMESTAMP (ADD_MONTHS(SYSTIMESTAMP, -1))
   GROUP BY department_id
   UNION ALL
   SELECT 'LAST_QUARTER', department_id, COUNT(*), AVG(salary)
   FROM employees AS OF TIMESTAMP (ADD_MONTHS(SYSTIMESTAMP, -3))
   GROUP BY department_id
)
SELECT department_id,
      MAX(CASE WHEN snapshot_date = 'CURRENT' THEN emp_count END) as current_count,
      MAX(CASE WHEN snapshot_date = 'LAST_MONTH' THEN emp_count END) as last_month_count,
      MAX(CASE WHEN snapshot_date = 'LAST_QUARTER' THEN emp_count END) as last_quarter_count,
      MAX(CASE WHEN snapshot_date = 'CURRENT' THEN avg_salary END) as current_avg_salary,
      MAX(CASE WHEN snapshot_date = 'LAST_MONTH' THEN avg_salary END) as last_month_avg_salary
FROM historical_snapshots
GROUP BY department_id;

-- Audit changes using Flashback Version Query
SELECT employee_id, 
      versions_starttime as change_time,
      versions_operation as operation_type,
      CASE versions_operation
          WHEN 'I' THEN 'INSERT'
          WHEN 'U' THEN 'UPDATE' 
          WHEN 'D' THEN 'DELETE'
      END as operation_description,
      first_name, last_name, salary
FROM employees
VERSIONS BETWEEN TIMESTAMP 
   (SYSTIMESTAMP - INTERVAL '30' DAY) AND SYSTIMESTAMP
WHERE employee_id IN (100, 101, 102)
ORDER BY employee_id, versions_starttime;

-- Performance considerations
-- Flashback queries may be slower due to undo data access
-- Use appropriate time windows to limit data scanning
-- Consider Flashback Archive for long-term historical data
-- Monitor undo tablespace usage for Flashback operations`
   },
   {
       id: 50,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement Oracle partitioning strategies for performance optimization?',
       answer: 'Oracle partitioning divides large tables into smaller, manageable pieces. Different partitioning strategies include range, hash, list, and composite partitioning for optimal performance.',
       language: 'Oracle SQL',
       code: `-- Range Partitioning by Date (most common for time-series data)
CREATE TABLE sales_range_partitioned (
   sale_id NUMBER,
   sale_date DATE,
   customer_id NUMBER,
   product_id NUMBER,
   amount NUMBER
)
PARTITION BY RANGE (sale_date) (
   PARTITION p_2022 VALUES LESS THAN (DATE '2023-01-01'),
   PARTITION p_2023 VALUES LESS THAN (DATE '2024-01-01'),
   PARTITION p_2024 VALUES LESS THAN (DATE '2025-01-01'),
   PARTITION p_future VALUES LESS THAN (MAXVALUE)
);

-- Hash Partitioning for even distribution
CREATE TABLE customers_hash_partitioned (
   customer_id NUMBER,
   customer_name VARCHAR2(100),
   region VARCHAR2(50),
   created_date DATE
)
PARTITION BY HASH (customer_id) PARTITIONS 8;

-- List Partitioning by specific values
CREATE TABLE sales_list_partitioned (
   sale_id NUMBER,
   region VARCHAR2(20),
   sale_date DATE,
   amount NUMBER
)
PARTITION BY LIST (region) (
   PARTITION p_north VALUES ('NORTH', 'NORTHEAST'),
   PARTITION p_south VALUES ('SOUTH', 'SOUTHEAST'),
   PARTITION p_west VALUES ('WEST', 'NORTHWEST'),
   PARTITION p_east VALUES ('EAST'),
   PARTITION p_others VALUES (DEFAULT)
);

-- Composite Partitioning (Range-Hash)
CREATE TABLE orders_composite_partitioned (
   order_id NUMBER,
   order_date DATE,
   customer_id NUMBER,
   amount NUMBER
)
PARTITION BY RANGE (order_date)
SUBPARTITION BY HASH (customer_id) SUBPARTITIONS 4 (
   PARTITION p_2023 VALUES LESS THAN (DATE '2024-01-01'),
   PARTITION p_2024 VALUES LESS THAN (DATE '2025-01-01'),
   PARTITION p_future VALUES LESS THAN (MAXVALUE)
);

-- Interval Partitioning (automatic partition creation)
CREATE TABLE sales_interval_partitioned (
   sale_id NUMBER,
   sale_date DATE,
   amount NUMBER
)
PARTITION BY RANGE (sale_date)
INTERVAL (NUMTOYMINTERVAL(1, 'MONTH')) (
   PARTITION p_start VALUES LESS THAN (DATE '2024-01-01')
);

-- Partition-wise joins for performance
SELECT /*+ USE_HASH(s o) */ 
      s.sale_date, s.amount, o.order_status
FROM sales_range_partitioned s
JOIN orders_composite_partitioned o 
   ON s.customer_id = o.customer_id
   AND s.sale_date = o.order_date
WHERE s.sale_date >= DATE '2024-01-01'
 AND s.sale_date < DATE '2024-02-01';

-- Partition elimination demonstration
EXPLAIN PLAN FOR
SELECT * FROM sales_range_partitioned
WHERE sale_date BETWEEN DATE '2024-01-01' AND DATE '2024-01-31';

-- View partition information
SELECT table_name, partition_name, high_value, num_rows, blocks
FROM user_tab_partitions
WHERE table_name = 'SALES_RANGE_PARTITIONED'
ORDER BY partition_position;

-- Partition maintenance operations
-- Add new partition
ALTER TABLE sales_range_partitioned 
ADD PARTITION p_2025 VALUES LESS THAN (DATE '2026-01-01');

-- Drop old partition
ALTER TABLE sales_range_partitioned 
DROP PARTITION p_2022;

-- Split partition
ALTER TABLE sales_range_partitioned 
SPLIT PARTITION p_future AT (DATE '2026-01-01')
INTO (PARTITION p_2025_new, PARTITION p_future_new);

-- Merge partitions
ALTER TABLE sales_range_partitioned 
MERGE PARTITIONS p_2023, p_2024 INTO PARTITION p_2023_2024;

-- Partition exchange (fast data movement)
CREATE TABLE sales_staging (
   sale_id NUMBER,
   sale_date DATE,
   customer_id NUMBER,
   product_id NUMBER,
   amount NUMBER
);

-- Load data into staging table
INSERT INTO sales_staging VALUES (1, DATE '2024-06-15', 100, 200, 1500);

-- Exchange staging table with partition
ALTER TABLE sales_range_partitioned 
EXCHANGE PARTITION p_2024 WITH TABLE sales_staging
INCLUDING INDEXES WITHOUT VALIDATION;

-- Parallel operations on partitioned tables
SELECT /*+ PARALLEL(s, 4) */
      EXTRACT(MONTH FROM sale_date) as month,
      COUNT(*) as sales_count,
      SUM(amount) as total_amount
FROM sales_range_partitioned s
WHERE sale_date >= DATE '2024-01-01'
GROUP BY EXTRACT(MONTH FROM sale_date);

-- Partition pruning with bind variables
SELECT * FROM sales_range_partitioned
WHERE sale_date >= :start_date
 AND sale_date < :end_date;

-- Reference partitioning (child table inherits parent's partitioning)
CREATE TABLE order_items_ref_partitioned (
   order_id NUMBER,
   item_id NUMBER,
   product_id NUMBER,
   quantity NUMBER,
   price NUMBER,
   CONSTRAINT fk_order_items FOREIGN KEY (order_id) 
       REFERENCES orders_composite_partitioned (order_id)
)
PARTITION BY REFERENCE (fk_order_items);

-- Cleanup
DROP TABLE sales_range_partitioned;
DROP TABLE customers_hash_partitioned;
DROP TABLE sales_list_partitioned;
DROP TABLE orders_composite_partitioned;
DROP TABLE sales_interval_partitioned;
DROP TABLE sales_staging;
DROP TABLE order_items_ref_partitioned;`
   },

   // More questions continue...
   {
       id: 51,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you use Oracle Regular Expressions (REGEXP) for complex pattern matching and data validation?',
       answer: 'Oracle provides REGEXP functions like REGEXP_LIKE, REGEXP_SUBSTR, REGEXP_REPLACE, and REGEXP_INSTR for powerful pattern matching and text processing.',
       language: 'Oracle SQL',
       code: `-- Basic pattern matching with REGEXP_LIKE
SELECT employee_id, first_name, email
FROM employees
WHERE REGEXP_LIKE(email, '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$');

-- Extract parts of strings with REGEXP_SUBSTR
SELECT phone_number,
      REGEXP_SUBSTR(phone_number, '\d{3}', 1, 1) as area_code,
      REGEXP_SUBSTR(phone_number, '\d{3}', 1, 2) as exchange,
      REGEXP_SUBSTR(phone_number, '\d{4}', 1, 1) as number
FROM employees
WHERE phone_number IS NOT NULL;

-- Advanced email domain extraction
SELECT email,
      REGEXP_SUBSTR(email, '[^@]+', 1, 1) as username,
      REGEXP_SUBSTR(email, '[^@]+', 1, 2) as domain,
      REGEXP_SUBSTR(email, '\.([^.]+)$', 1, 1, NULL, 1) as top_level_domain
FROM employees
WHERE email IS NOT NULL;

-- Complex pattern matching for data validation
WITH data_validation AS (
   SELECT employee_id, first_name, last_name, email, phone_number,
          -- Validate name contains only letters and spaces
          CASE WHEN REGEXP_LIKE(first_name, '^[A-Za-z\s]+$') THEN 'VALID' ELSE 'INVALID' END as first_name_valid,
          -- Validate email format
          CASE WHEN REGEXP_LIKE(email, '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$') THEN 'VALID' ELSE 'INVALID' END as email_valid,
          -- Validate phone format (various patterns)
          CASE WHEN REGEXP_LIKE(phone_number, '^(\+1[-.\s]?)?\(?\d{3}\)?[-.\s]?\d{3}[-.\s]?\d{4}$') THEN 'VALID' ELSE 'INVALID' END as phone_valid
   FROM employees
)
SELECT * FROM data_validation
WHERE first_name_valid = 'INVALID' OR email_valid = 'INVALID' OR phone_valid = 'INVALID';

-- Clean and standardize data using REGEXP_REPLACE
SELECT phone_number as original_phone,
      REGEXP_REPLACE(phone_number, '[^0-9]', '') as digits_only,
      REGEXP_REPLACE(phone_number, '^(\d{3})(\d{3})(\d{4})$', '(\1) \2-\3') as formatted_phone,
      REGEXP_REPLACE(UPPER(first_name), '[^A-Z ]', '') as clean_name
FROM employees
WHERE phone_number IS NOT NULL;

-- Extract structured data from unstructured text
WITH log_data AS (
   SELECT 'ERROR 2024-01-15 14:30:22 User john.doe failed login attempt from 192.168.1.100' as log_entry FROM dual
   UNION ALL
   SELECT 'INFO 2024-01-15 14:31:05 User jane.smith successful login from 10.0.0.50' FROM dual
   UNION ALL
   SELECT 'WARN 2024-01-15 14:32:10 User admin password expires in 5 days' FROM dual
)
SELECT log_entry,
      REGEXP_SUBSTR(log_entry, '(ERROR|INFO|WARN)', 1, 1) as log_level,
      REGEXP_SUBSTR(log_entry, '\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', 1, 1) as timestamp_str,
      REGEXP_SUBSTR(log_entry, 'User (\w+\.?\w*)', 1, 1, NULL, 1) as username,
      REGEXP_SUBSTR(log_entry, '(\d{1,3}\.){3}\d{1,3}', 1, 1) as ip_address
FROM log_data;

-- Advanced pattern matching with sub-expressions
SELECT customer_address,
      REGEXP_SUBSTR(customer_address, '(\d+)\s+([A-Za-z\s]+),\s*([A-Za-z\s]+),\s*([A-Z]{2})\s+(\d{5})', 1, 1, NULL, 1) as street_number,
      REGEXP_SUBSTR(customer_address, '(\d+)\s+([A-Za-z\s]+),\s*([A-Za-z\s]+),\s*([A-Z]{2})\s+(\d{5})', 1, 1, NULL, 2) as street_name,
      REGEXP_SUBSTR(customer_address, '(\d+)\s+([A-Za-z\s]+),\s*([A-Za-z\s]+),\s*([A-Z]{2})\s+(\d{5})', 1, 1, NULL, 3) as city,
      REGEXP_SUBSTR(customer_address, '(\d+)\s+([A-Za-z\s]+),\s*([A-Za-z\s]+),\s*([A-Z]{2})\s+(\d{5})', 1, 1, NULL, 4) as state,
      REGEXP_SUBSTR(customer_address, '(\d+)\s+([A-Za-z\s]+),\s*([A-Za-z\s]+),\s*([A-Z]{2})\s+(\d{5})', 1, 1, NULL, 5) as zip_code
FROM (
   SELECT '123 Main Street, Springfield, IL 62701' as customer_address FROM dual
   UNION ALL
   SELECT '456 Oak Avenue, Chicago, IL 60601' FROM dual
);

-- Find and count pattern occurrences with REGEXP_COUNT
SELECT text_data,
      REGEXP_COUNT(text_data, '\b\w+\b') as word_count,
      REGEXP_COUNT(text_data, '\d+') as number_count,
      REGEXP_COUNT(text_data, '[A-Z]') as uppercase_count,
      REGEXP_COUNT(text_data, '\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b') as email_count
FROM (
   SELECT 'Contact John Doe at john.doe@company.com or call 555-1234. Alternative email: j.doe@backup.org' as text_data FROM dual
);

-- Complex validation rules
WITH validation_rules AS (
   SELECT employee_id, ssn, credit_card,
          -- SSN validation (XXX-XX-XXXX format)
          CASE WHEN REGEXP_LIKE(ssn, '^\d{3}-\d{2}-\d{4}$') THEN 'VALID' ELSE 'INVALID' END as ssn_format,
          -- Credit card validation (basic Luhn algorithm check)
          CASE WHEN REGEXP_LIKE(credit_card, '^[0-9]{13,19}$') THEN 'VALID_FORMAT' ELSE 'INVALID_FORMAT' END as cc_format,
          -- Strong password validation
          CASE WHEN REGEXP_LIKE(password, '^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)(?=.*[@$!%*?&])[A-Za-z\d@$!%*?&]{8,}$') 
               THEN 'STRONG' ELSE 'WEAK' END as password_strength
   FROM employee_sensitive_data
)
SELECT * FROM validation_rules
WHERE ssn_format = 'INVALID' OR cc_format = 'INVALID_FORMAT' OR password_strength = 'WEAK';

-- Text processing and cleanup
SELECT description as original,
      -- Remove extra whitespace
      REGEXP_REPLACE(description, '\s+', ' ') as normalized_spaces,
      -- Remove special characters except alphanumeric and spaces
      REGEXP_REPLACE(description, '[^A-Za-z0-9\s]', '') as alphanumeric_only,
      -- Extract hashtags
      REGEXP_SUBSTR(description, '#\w+', 1, 1) as first_hashtag,
      -- Extract mentions
      REGEXP_SUBSTR(description, '@\w+', 1, 1) as first_mention
FROM product_descriptions;`
   },

   // Continue with more advanced questions...
   {
       id: 52,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement advanced Oracle SQL security patterns and audit mechanisms?',
       answer: 'Oracle provides comprehensive security through database vault, fine-grained auditing, encryption, and access controls to protect sensitive data and track access patterns.',
       language: 'Oracle SQL',
       code: `-- Fine-Grained Auditing (FGA) for sensitive data access
BEGIN
   DBMS_FGA.ADD_POLICY(
       object_schema   => 'HR',
       object_name     => 'EMPLOYEES',
       policy_name     => 'SALARY_ACCESS_AUDIT',
       audit_condition => 'SALARY > 100000',
       audit_columns   => 'SALARY,COMMISSION_PCT',
       handler_schema  => 'HR',
       handler_module  => 'SALARY_AUDIT_HANDLER',
       enable          => TRUE,
       statement_types => 'SELECT,UPDATE'
   );
END;
/

-- Custom audit handler procedure
CREATE OR REPLACE PROCEDURE salary_audit_handler(
   object_schema VARCHAR2,
   object_name VARCHAR2,
   policy_name VARCHAR2
) AS
BEGIN
   INSERT INTO security_audit_log (
       audit_date, username, object_accessed, policy_triggered, ip_address
   ) VALUES (
       SYSDATE, USER, object_schema||'.'||object_name, policy_name,
       SYS_CONTEXT('USERENV', 'IP_ADDRESS')
   );
   
   -- Alert security team for sensitive access
   IF HOUR(SYSDATE) NOT BETWEEN 8 AND 18 THEN
       INSERT INTO security_alerts (alert_date, alert_type, username, details)
       VALUES (SYSDATE, 'AFTER_HOURS_SALARY_ACCESS', USER, 
               'High salary data accessed outside business hours');
   END IF;
END;
/

-- Transparent Data Encryption (TDE) for columns
ALTER TABLE employees MODIFY (ssn ENCRYPT USING 'AES128');
ALTER TABLE employees MODIFY (salary ENCRYPT USING 'AES192' IDENTIFIED BY "salary_key");

-- Application context for dynamic security
CREATE OR REPLACE CONTEXT user_security_ctx USING security_context_pkg;

-- Security context package
CREATE OR REPLACE PACKAGE security_context_pkg AS
   PROCEDURE set_user_context;
END;
/

CREATE OR REPLACE PACKAGE BODY security_context_pkg AS
   PROCEDURE set_user_context IS
       v_dept_id NUMBER;
       v_role VARCHAR2(50);
   BEGIN
       -- Get user's department and role
       SELECT department_id, job_role 
       INTO v_dept_id, v_role
       FROM user_profiles 
       WHERE username = USER;
       
       -- Set context attributes
       DBMS_SESSION.SET_CONTEXT('USER_SECURITY_CTX', 'DEPARTMENT_ID', v_dept_id);
       DBMS_SESSION.SET_CONTEXT('USER_SECURITY_CTX', 'USER_ROLE', v_role);
       DBMS_SESSION.SET_CONTEXT('USER_SECURITY_CTX', 'LOGIN_TIME', TO_CHAR(SYSDATE, 'HH24:MI:SS'));
   END;
END;
/

-- Logon trigger to set context
CREATE OR REPLACE TRIGGER set_security_context_trg
   AFTER LOGON ON DATABASE
BEGIN
   security_context_pkg.set_user_context;
END;
/

-- VPD policy using application context
CREATE OR REPLACE FUNCTION dept_security_policy(
   schema_var IN VARCHAR2,
   table_var IN VARCHAR2
) RETURN VARCHAR2 AS
   v_predicate VARCHAR2(200);
   v_user_role VARCHAR2(50);
   v_user_dept NUMBER;
BEGIN
   v_user_role := SYS_CONTEXT('USER_SECURITY_CTX', 'USER_ROLE');
   v_user_dept := TO_NUMBER(SYS_CONTEXT('USER_SECURITY_CTX', 'DEPARTMENT_ID'));
   
   CASE v_user_role
       WHEN 'ADMIN' THEN
           v_predicate := '1=1';  -- Full access
       WHEN 'MANAGER' THEN
           v_predicate := 'department_id IN (SELECT dept_id FROM manager_departments WHERE manager_id = '||v_user_dept||')';
       WHEN 'EMPLOYEE' THEN
           v_predicate := 'department_id = '||v_user_dept||' AND employee_id = '||USER;
       ELSE
           v_predicate := '1=0';  -- No access
   END CASE;
   
   RETURN v_predicate;
END;
/

-- Data masking views for different user roles
CREATE OR REPLACE VIEW employees_masked AS
SELECT employee_id,
      first_name,
      last_name,
      CASE 
          WHEN SYS_CONTEXT('USER_SECURITY_CTX', 'USER_ROLE') = 'ADMIN' THEN email
          ELSE REGEXP_REPLACE(email, '(.{2}).*(@.*)', '\1***\2')
      END as email,
      CASE 
          WHEN SYS_CONTEXT('USER_SECURITY_CTX', 'USER_ROLE') IN ('ADMIN', 'HR') THEN phone_number
          ELSE REGEXP_REPLACE(phone_number, '(\d{3}).*(\d{4})', '\1-***-\2')
      END as phone_number,
      hire_date,
      job_id,
      CASE 
          WHEN SYS_CONTEXT('USER_SECURITY_CTX', 'USER_ROLE') IN ('ADMIN', 'PAYROLL') THEN salary
          WHEN SYS_CONTEXT('USER_SECURITY_CTX', 'USER_ROLE') = 'MANAGER' THEN 
              CASE WHEN salary < 50000 THEN 'LOW'
                   WHEN salary < 100000 THEN 'MEDIUM'
                   ELSE 'HIGH' END
          ELSE NULL
      END as salary,
      department_id
FROM employees;

-- Database Vault command rules (requires Database Vault)
-- Prevent unauthorized DDL operations
BEGIN
   DVSYS.DBMS_MACADM.CREATE_COMMAND_RULE(
       command         => 'ALTER SYSTEM',
       rule_set_name   => 'Trusted_Path',
       object_owner    => '%',
       object_name     => '%',
       enabled         => 'Y'
   );
END;
/

-- Secure audit trail query
SELECT audit_date, username, action_taken, object_name, 
      client_info, os_username, terminal,
      CASE 
          WHEN TO_NUMBER(TO_CHAR(audit_date, 'HH24')) NOT BETWEEN 8 AND 18 
          THEN 'AFTER_HOURS'
          ELSE 'BUSINESS_HOURS'
      END as access_time_category
FROM (
   -- Standard audit trail
   SELECT timestamp as audit_date, username, action_name as action_taken, 
          obj_name as object_name, client_info, os_username, terminal
   FROM dba_audit_trail
   WHERE obj_name IN ('EMPLOYEES', 'SALARY_HISTORY', 'PAYROLL')
   
   UNION ALL
   
   -- FGA audit trail
   SELECT timestamp as audit_date, db_user as username, 
          'FGA_'||policy_name as action_taken, object_name,
          NULL as client_info, os_user as os_username, userhost as terminal
   FROM dba_fga_audit_trail
   WHERE object_name IN ('EMPLOYEES', 'SALARY_HISTORY')
)
ORDER BY audit_date DESC;

-- Privilege analysis and monitoring
-- Create privilege capture
BEGIN
   DBMS_PRIVILEGE_CAPTURE.CREATE_CAPTURE(
       name => 'APP_PRIVILEGE_ANALYSIS',
       type => DBMS_PRIVILEGE_CAPTURE.G_DATABASE,
       description => 'Analyze application privilege usage'
   );
   
   DBMS_PRIVILEGE_CAPTURE.START_CAPTURE('APP_PRIVILEGE_ANALYSIS');
END;
/

-- After running application for analysis period
BEGIN
   DBMS_PRIVILEGE_CAPTURE.STOP_CAPTURE('APP_PRIVILEGE_ANALYSIS');
   DBMS_PRIVILEGE_CAPTURE.GENERATE_RESULT('APP_PRIVILEGE_ANALYSIS');
END;
/

-- Query captured privileges
SELECT username, obj_priv, object_owner, object_name, used_role
FROM dba_used_objprivs
WHERE capture = 'APP_PRIVILEGE_ANALYSIS'
ORDER BY username, object_name;

-- Security monitoring dashboard query
WITH security_metrics AS (
   SELECT 
       COUNT(CASE WHEN audit_date >= TRUNC(SYSDATE) THEN 1 END) as today_access_count,
       COUNT(CASE WHEN audit_date >= TRUNC(SYSDATE) AND 
                       TO_NUMBER(TO_CHAR(audit_date, 'HH24')) NOT BETWEEN 8 AND 18 
                  THEN 1 END) as after_hours_access,
       COUNT(CASE WHEN audit_date >= TRUNC(SYSDATE) AND 
                       action_taken LIKE '%SALARY%' 
                  THEN 1 END) as salary_access_count,
       COUNT(DISTINCT username) as unique_users_today,
       COUNT(CASE WHEN audit_date >= TRUNC(SYSDATE) AND 
                       username NOT IN (SELECT username FROM authorized_users) 
                  THEN 1 END) as unauthorized_attempts
   FROM (
       SELECT timestamp as audit_date, username, action_name as action_taken
       FROM dba_audit_trail
       WHERE timestamp >= TRUNC(SYSDATE) - 7
       UNION ALL
       SELECT timestamp, db_user, policy_name
       FROM dba_fga_audit_trail
       WHERE timestamp >= TRUNC(SYSDATE) - 7
   )
)
SELECT 
   today_access_count,
   after_hours_access,
   ROUND((after_hours_access / NULLIF(today_access_count, 0)) * 100, 2) as after_hours_pct,
   salary_access_count,
   unique_users_today,
   unauthorized_attempts,
   CASE 
       WHEN unauthorized_attempts > 0 THEN 'HIGH'
       WHEN after_hours_pct > 20 THEN 'MEDIUM'
       ELSE 'LOW'
   END as risk_level
FROM security_metrics;

-- Encrypt sensitive data in transit
SELECT UTL_RAW.CAST_TO_VARCHAR2(
   DBMS_CRYPTO.DECRYPT(
       src => UTL_RAW.CAST_TO_RAW(encrypted_ssn),
       typ => DBMS_CRYPTO.AES_CBC_PKCS5,
       key => UTL_RAW.CAST_TO_RAW('MySecretKey12345')
   )
) as decrypted_ssn
FROM employee_encrypted
WHERE employee_id = 100;`
   },

   // Final set of questions (53-60)
   {
       id: 53,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement complex Oracle SQL solutions for real-time data streaming and CDC (Change Data Capture)?',
       answer: 'Oracle provides multiple CDC mechanisms including triggers, Oracle Streams, GoldenGate, and Flashback for capturing and processing data changes in real-time.',
       language: 'Oracle SQL',
       code: `-- Trigger-based CDC implementation
CREATE TABLE employee_changes_log (
   change_id NUMBER GENERATED BY DEFAULT AS IDENTITY,
   table_name VARCHAR2(30),
   operation_type VARCHAR2(10),
   changed_by VARCHAR2(30),
   change_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
   old_values CLOB,
   new_values CLOB,
   change_vector RAW(16)
);

-- CDC trigger for employees table
CREATE OR REPLACE TRIGGER employees_cdc_trigger
   AFTER INSERT OR UPDATE OR DELETE ON employees
   FOR EACH ROW
DECLARE
   v_operation VARCHAR2(10);
   v_old_values CLOB;
   v_new_values CLOB;
BEGIN
   -- Determine operation type
   CASE
       WHEN INSERTING THEN v_operation := 'INSERT';
       WHEN UPDATING THEN v_operation := 'UPDATE';
       WHEN DELETING THEN v_operation := 'DELETE';
   END CASE;
   
   -- Build JSON for old values
   IF NOT INSERTING THEN
       v_old_values := JSON_OBJECT(
           'employee_id' VALUE :OLD.employee_id,
           'first_name' VALUE :OLD.first_name,
           'last_name' VALUE :OLD.last_name,
           'email' VALUE :OLD.email,
           'salary' VALUE :OLD.salary,
           'department_id' VALUE :OLD.department_id
       );
   END IF;
   
   -- Build JSON for new values
   IF NOT DELETING THEN
       v_new_values := JSON_OBJECT(
           'employee_id' VALUE :NEW.employee_id,
           'first_name' VALUE :NEW.first_name,
           'last_name' VALUE :NEW.last_name,
           'email' VALUE :NEW.email,
           'salary' VALUE :NEW.salary,
           'department_id' VALUE :NEW.department_id
       );
   END IF;
   
   -- Log the change
   INSERT INTO employee_changes_log (
       table_name, operation_type, changed_by, old_values, new_values, change_vector
   ) VALUES (
       'EMPLOYEES', v_operation, USER, v_old_values, v_new_values, SYS_GUID()
   );
   
   -- Publish change to message queue for real-time processing
   publish_change_event(v_operation, 'EMPLOYEES', v_old_values, v_new_values);
END;
/

-- Real-time change processing procedure
CREATE OR REPLACE PROCEDURE publish_change_event(
   p_operation VARCHAR2,
   p_table_name VARCHAR2,
   p_old_values CLOB,
   p_new_values CLOB
) AS
   v_message SYS.AQ$_JMS_TEXT_MESSAGE;
   v_enqueue_options DBMS_AQ.ENQUEUE_OPTIONS_T;
   v_message_properties DBMS_AQ.MESSAGE_PROPERTIES_T;
   v_msgid RAW(16);
BEGIN
   -- Create message payload
   v_message := SYS.AQ$_JMS_TEXT_MESSAGE.CONSTRUCT;
   v_message.SET_TEXT(JSON_OBJECT(
       'operation' VALUE p_operation,
       'table_name' VALUE p_table_name,
       'timestamp' VALUE TO_CHAR(SYSTIMESTAMP, 'YYYY-MM-DD"T"HH24:MI:SS.FF3"Z"'),
       'old_values' VALUE JSON_QUERY(p_old_values, '$'),
       'new_values' VALUE JSON_QUERY(p_new_values, '$')
   ));
   
   -- Set message properties
   v_message_properties.priority := 1;
   v_message_properties.expiration := DBMS_AQ.NEVER;
   
   -- Enqueue message
   DBMS_AQ.ENQUEUE(
       queue_name => 'CDC_QUEUE',
       enqueue_options => v_enqueue_options,
       message_properties => v_message_properties,
       payload => v_message,
       msgid => v_msgid
   );
   
   COMMIT;
EXCEPTION
   WHEN OTHERS THEN
       -- Log error but don't fail the main transaction
       INSERT INTO cdc_error_log (error_date, error_message, table_name, operation)
       VALUES (SYSDATE, SQLERRM, p_table_name, p_operation);
       COMMIT;
END;
/

-- Query CDC log with analytics
SELECT 
   operation_type,
   table_name,
   DATE_TRUNC('HOUR', change_timestamp) as hour_bucket,
   COUNT(*) as change_count,
   COUNT(DISTINCT changed_by) as unique_users,
   -- Extract specific field changes for analysis
   SUM(CASE WHEN JSON_EXISTS(old_values, '$.salary') AND JSON_EXISTS(new_values, '$.salary')
            AND JSON_VALUE(old_values, '$.salary') != JSON_VALUE(new_values, '$.salary')
            THEN 1 ELSE 0 END) as salary_changes,
   -- Lag analysis for change frequency
   LAG(COUNT(*)) OVER (PARTITION BY operation_type ORDER BY DATE_TRUNC('HOUR', change_timestamp)) as prev_hour_changes
FROM employee_changes_log
WHERE change_timestamp >= SYSTIMESTAMP - INTERVAL '24' HOUR
GROUP BY operation_type, table_name, DATE_TRUNC('HOUR', change_timestamp)
ORDER BY hour_bucket DESC, operation_type;

-- Advanced CDC with Oracle Streams (conceptual)
-- Note: Actual Streams setup requires DBA privileges
/*
-- Create Streams administrator
GRANT DBA TO streams_admin;
BEGIN
   DBMS_STREAMS_AUTH.GRANT_ADMIN_PRIVILEGE(
       grantee => 'streams_admin'
   );
END;
/

-- Configure Streams capture process
BEGIN
   DBMS_STREAMS_ADM.ADD_TABLE_RULES(
       table_name => 'hr.employees',
       streams_type => 'capture',
       streams_name => 'capture_emp_changes',
       queue_name => 'streams_queue',
       include_dml => TRUE,
       include_ddl => FALSE
   );
END;
/
*/

-- Materialized View for CDC (log-based)
CREATE MATERIALIZED VIEW LOG ON employees WITH ROWID, SEQUENCE (
   employee_id, first_name, last_name, email, salary, department_id
) INCLUDING NEW VALUES;

CREATE MATERIALIZED VIEW employees_mv
REFRESH FAST ON COMMIT
AS
SELECT employee_id, first_name, last_name, email, salary, department_id,
      SYSDATE as last_refresh
FROM employees;

-- Query materialized view log for changes
SELECT ml.employee_id, ml.dmltype$$, ml.old_new$$, ml.change_vector$$,
      ml.sequence$$, ml.snaptime$$
FROM mlog$_employees ml
WHERE ml.snaptime$$ > SYSDATE - 1/24  -- Last hour
ORDER BY ml.sequence$$;

-- Real-time data synchronization example
DECLARE
   v_cursor SYS_REFCURSOR;
   v_change_record employee_changes_log%ROWTYPE;
   v_batch_size NUMBER := 100;
   v_processed NUMBER := 0;
BEGIN
   -- Process changes in batches
   OPEN v_cursor FOR
       SELECT * FROM employee_changes_log
       WHERE change_timestamp > SYSDATE - 1/1440  -- Last minute
         AND processed_flag IS NULL
       ORDER BY change_timestamp
       FOR UPDATE SKIP LOCKED;
   
   LOOP
       FETCH v_cursor BULK COLLECT INTO v_change_record LIMIT v_batch_size;
       EXIT WHEN v_change_record.COUNT = 0;
       
       -- Process each change
       FOR i IN 1..v_change_record.COUNT LOOP
           -- Sync to external system
           sync_to_external_system(
               v_change_record(i).operation_type,
               v_change_record(i).new_values
           );
           
           -- Mark as processed
           UPDATE employee_changes_log 
           SET processed_flag = 'Y', processed_timestamp = SYSDATE
           WHERE change_id = v_change_record(i).change_id;
           
           v_processed := v_processed + 1;
       END LOOP;
       
       COMMIT;
   END LOOP;
   
   CLOSE v_cursor;
   
   DBMS_OUTPUT.PUT_LINE('Processed ' || v_processed || ' changes');
END;
/

-- Performance monitoring for CDC
SELECT 
   table_name,
   operation_type,
   COUNT(*) as total_changes,
   MIN(change_timestamp) as first_change,
   MAX(change_timestamp) as last_change,
   AVG(EXTRACT(SECOND FROM (processed_timestamp - change_timestamp))) as avg_processing_latency_sec,
   COUNT(CASE WHEN processed_flag IS NULL THEN 1 END) as pending_changes
FROM employee_changes_log
WHERE change_timestamp >= TRUNC(SYSDATE)
GROUP BY table_name, operation_type
ORDER BY total_changes DESC;`
   },

   // Additional questions (54-60) for completeness
   {
       id: 54,
       category: 'intermediate',
       difficulty: 'intermediate',
       question: 'How do you work with Oracle JSON data types and functions?',
       answer: 'Oracle provides native JSON support with JSON data type, JSON functions for querying and manipulating JSON data, and SQL/JSON path expressions.',
       language: 'Oracle SQL',
       code: `-- Create table with JSON column
CREATE TABLE customer_profiles (
   customer_id NUMBER PRIMARY KEY,
   profile_data JSON,
   created_date DATE DEFAULT SYSDATE
);

-- Insert JSON data
INSERT INTO customer_profiles VALUES (1, JSON_OBJECT(
   'name' VALUE 'John Doe',
   'age' VALUE 30,
   'email' VALUE 'john.doe@email.com',
   'address' VALUE JSON_OBJECT(
       'street' VALUE '123 Main St',
       'city' VALUE 'Springfield',
       'zipcode' VALUE '12345'
   ),
   'preferences' VALUE JSON_ARRAY('email', 'sms'),
   'active' VALUE true
), SYSDATE);

-- Query JSON data using JSON_VALUE
SELECT customer_id,
      JSON_VALUE(profile_data, '$.name') as customer_name,
      JSON_VALUE(profile_data, '$.age' RETURNING NUMBER) as customer_age,
      JSON_VALUE(profile_data, '$.address.city') as city
FROM customer_profiles;

-- Query with JSON_QUERY for complex objects
SELECT customer_id,
      JSON_QUERY(profile_data, '$.address') as full_address,
      JSON_QUERY(profile_data, '$.preferences') as preferences_array
FROM customer_profiles;

-- Use JSON_TABLE to convert JSON to relational format
SELECT customer_id, jt.*
FROM customer_profiles cp,
    JSON_TABLE(cp.profile_data, '$'
        COLUMNS (
            customer_name VARCHAR2(100) PATH '$.name',
            customer_age NUMBER PATH '$.age',
            email VARCHAR2(100) PATH '$.email',
            street VARCHAR2(100) PATH '$.address.street',
            city VARCHAR2(50) PATH '$.address.city',
            zipcode VARCHAR2(10) PATH '$.address.zipcode'
        )
    ) jt;

-- Update JSON data
UPDATE customer_profiles 
SET profile_data = JSON_TRANSFORM(profile_data,
   SET '$.age' = 31,
   SET '$.address.street' = '456 Oak Ave'
)
WHERE customer_id = 1;

-- Add new JSON properties
UPDATE customer_profiles 
SET profile_data = JSON_TRANSFORM(profile_data,
   SET '$.last_login' = SYSTIMESTAMP,
   SET '$.loyalty_points' = 150
)
WHERE customer_id = 1;`
   },
   {
       id: 55,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you implement Oracle SQL solutions for time-series analysis and forecasting?',
       answer: 'Use Oracle analytical functions, MODEL clause, and statistical functions for time-series analysis including trend detection, seasonality, and forecasting.',
       language: 'Oracle SQL',
       code: `-- Time-series analysis with moving averages and trend detection
WITH time_series_data AS (
   SELECT date_column, sales_amount,
          -- Simple moving average
          AVG(sales_amount) OVER (ORDER BY date_column 
                                 ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) as sma_7day,
          -- Exponential moving average approximation
          AVG(sales_amount) OVER (ORDER BY date_column 
                                 ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) as ema_3day,
          -- Linear trend using regression
          REGR_SLOPE(sales_amount, ROW_NUMBER() OVER (ORDER BY date_column)) 
          OVER (ORDER BY date_column ROWS BETWEEN 29 PRECEDING AND CURRENT ROW) as trend_slope,
          -- Seasonal decomposition
          AVG(sales_amount) OVER (PARTITION BY EXTRACT(DOW FROM date_column)) as day_of_week_avg,
          sales_amount - AVG(sales_amount) OVER (PARTITION BY EXTRACT(DOW FROM date_column)) as deseasonalized
   FROM daily_sales
   WHERE date_column >= ADD_MONTHS(SYSDATE, -12)
)
SELECT date_column, sales_amount, sma_7day, trend_slope,
      CASE 
          WHEN trend_slope > 0.1 THEN 'UPWARD_TREND'
          WHEN trend_slope < -0.1 THEN 'DOWNWARD_TREND'
          ELSE 'STABLE'
      END as trend_direction
FROM time_series_data
ORDER BY date_column;

-- Forecasting using Oracle MODEL clause
SELECT date_column, actual_sales, predicted_sales
FROM (
   SELECT date_column, sales_amount as actual_sales
   FROM daily_sales
   WHERE date_column <= SYSDATE
) 
MODEL
   PARTITION BY (1 as partition_id)
   DIMENSION BY (ROW_NUMBER() OVER (ORDER BY date_column) as rn)
   MEASURES (date_column, actual_sales, 0 as predicted_sales)
   RULES (
       predicted_sales[rn] = CASE 
           WHEN rn <= 30 THEN actual_sales[rn]  -- Use actual for first 30 days
           ELSE (actual_sales[rn-1] * 0.7 + actual_sales[rn-7] * 0.3)  -- Simple forecast
       END
   );`
   },
   {
       id: 56,
       category: 'advanced',
       difficulty: 'advanced',
       question: 'How do you handle Oracle SQL performance issues with large result sets and memory management?',
       answer: 'Use techniques like bulk processing, cursor management, parallel processing, and result set pagination to handle large data volumes efficiently.',
       language: 'Oracle SQL',
       code: `-- Bulk processing with FORALL and BULK COLLECT
DECLARE
   TYPE emp_id_array IS TABLE OF employees.employee_id%TYPE;
   TYPE salary_array IS TABLE OF employees.salary%TYPE;
   
   v_emp_ids emp_id_array;
   v_salaries salary_array;
   v_batch_size CONSTANT NUMBER := 10000;
   
   CURSOR emp_cursor IS
       SELECT employee_id, salary
       FROM employees
       WHERE department_id IN (10, 20, 30);
BEGIN
   OPEN emp_cursor;
   LOOP
       FETCH emp_cursor BULK COLLECT INTO v_emp_ids, v_salaries LIMIT v_batch_size;
       
       -- Process batch
       FORALL i IN 1..v_emp_ids.COUNT
           UPDATE employee_bonuses 
           SET bonus_amount = v_salaries(i) * 0.1
           WHERE employee_id = v_emp_ids(i);
       
       COMMIT;
       EXIT WHEN emp_cursor%NOTFOUND;
   END LOOP;
   CLOSE emp_cursor;
END;
/

-- Efficient pagination for large result sets
SELECT employee_id, first_name, last_name, salary
FROM (
   SELECT employee_id, first_name, last_name, salary,
          ROW_NUMBER() OVER (ORDER BY employee_id) as rn
   FROM employees
   WHERE department_id = 50
)
WHERE rn BETWEEN 10001 AND 20000;  -- Page 2 of 10,000 records per page

-- Memory-efficient cursor processing
DECLARE
   CURSOR large_cursor IS
       SELECT employee_id, salary, department_id
       FROM employees
       ORDER BY employee_id;
   
   v_employee large_cursor%ROWTYPE;
   v_total_processed NUMBER := 0;
BEGIN
   FOR v_employee IN large_cursor LOOP
       -- Process individual record
       update_employee_metrics(v_employee.employee_id, v_employee.salary);
       
       v_total_processed := v_total_processed + 1;
       
       -- Commit every 1000 records to manage memory
       IF MOD(v_total_processed, 1000) = 0 THEN
           COMMIT;
       END IF;
   END LOOP;
   
   COMMIT;
END;
/`
   }
];

// Export for use in other modules if needed
if (typeof module !== 'undefined' && module.exports) {
   module.exports = oracleSqlQuestions;
}

       

       




       


        
       
        // Combine all questions
        const allQuestions = [...oracleSqlQuestions, ...additionalQuestions];

        // Load questions when page loads
        function loadQuestions() {
            const container = document.getElementById('questionsContainer');
            container.innerHTML = '';
            
            allQuestions.forEach(question => {
                const questionElement = createQuestionElement(question);
                container.appendChild(questionElement);
            });
        }

        // Initialize questions on page load
        document.addEventListener('DOMContentLoaded', function() {
            loadQuestions();
        });
    </script>
</body>
</html>
